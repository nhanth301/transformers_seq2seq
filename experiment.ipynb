{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8537196,"sourceType":"datasetVersion","datasetId":5099533}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyvi torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:53:56.713088Z","iopub.execute_input":"2024-06-06T08:53:56.713793Z","iopub.status.idle":"2024-06-06T08:54:08.943918Z","shell.execute_reply.started":"2024-06-06T08:53:56.713765Z","shell.execute_reply":"2024-06-06T08:54:08.942833Z"},"trusted":true},"execution_count":263,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyvi in /opt/conda/lib/python3.10/site-packages (0.1.1)\nRequirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\nRequirement already satisfied: sklearn-crfsuite in /opt/conda/lib/python3.10/site-packages (from pyvi) (0.3.6)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.2.0)\nRequirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.10)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.66.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nimport numpy as np\nimport spacy\nimport torchtext\nimport tqdm\nimport random\nfrom spacy.lang.vi import Vietnamese\nfrom spacy.lang.en import English\nfrom torch.utils.data import Dataset, random_split\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:08.946577Z","iopub.execute_input":"2024-06-06T08:54:08.947216Z","iopub.status.idle":"2024-06-06T08:54:08.955706Z","shell.execute_reply.started":"2024-06-06T08:54:08.947175Z","shell.execute_reply":"2024-06-06T08:54:08.954520Z"},"trusted":true},"execution_count":264,"outputs":[]},{"cell_type":"code","source":"seed = 1234\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:08.957129Z","iopub.execute_input":"2024-06-06T08:54:08.957496Z","iopub.status.idle":"2024-06-06T08:54:08.970469Z","shell.execute_reply.started":"2024-06-06T08:54:08.957460Z","shell.execute_reply":"2024-06-06T08:54:08.969738Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"code","source":"def load_data(path):\n    data = []\n    with open(path,'r') as file:\n        for line in file.readlines():\n            splitted_line = line.split('\\t')\n            eng = splitted_line[0]\n            vi = splitted_line[1]\n            data.append({'vi':vi, \n                         'en':eng})\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:08.973094Z","iopub.execute_input":"2024-06-06T08:54:08.973605Z","iopub.status.idle":"2024-06-06T08:54:08.981785Z","shell.execute_reply.started":"2024-06-06T08:54:08.973577Z","shell.execute_reply":"2024-06-06T08:54:08.980877Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, index):\n        return self.data[index]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:08.982982Z","iopub.execute_input":"2024-06-06T08:54:08.983261Z","iopub.status.idle":"2024-06-06T08:54:08.992870Z","shell.execute_reply.started":"2024-06-06T08:54:08.983239Z","shell.execute_reply":"2024-06-06T08:54:08.992058Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"code","source":"dataset = CustomDataset(load_data('/kaggle/input/languagedata/data/vie.txt'))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:08.993875Z","iopub.execute_input":"2024-06-06T08:54:08.994133Z","iopub.status.idle":"2024-06-06T08:54:09.036639Z","shell.execute_reply.started":"2024-06-06T08:54:08.994112Z","shell.execute_reply":"2024-06-06T08:54:09.035993Z"},"trusted":true},"execution_count":268,"outputs":[]},{"cell_type":"code","source":"#7:2:1\ntotal_samples = len(dataset)\ntrain_size = int(0.8 * total_samples)\nval_size = int(0.1 * total_samples)\ntest_size = total_samples - train_size - val_size","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:09.037706Z","iopub.execute_input":"2024-06-06T08:54:09.038074Z","iopub.status.idle":"2024-06-06T08:54:09.043754Z","shell.execute_reply.started":"2024-06-06T08:54:09.038040Z","shell.execute_reply":"2024-06-06T08:54:09.042899Z"},"trusted":true},"execution_count":269,"outputs":[]},{"cell_type":"code","source":"train_data, valid_data, test_data = random_split(dataset, [train_size, val_size, test_size])\nprint(\"Số lượng mẫu trong tập train:\", len(train_data))\nprint(\"Số lượng mẫu trong tập validation:\", len(valid_data))\nprint(\"Số lượng mẫu trong tập test:\", len(test_data))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:09.044935Z","iopub.execute_input":"2024-06-06T08:54:09.045276Z","iopub.status.idle":"2024-06-06T08:54:09.055506Z","shell.execute_reply.started":"2024-06-06T08:54:09.045246Z","shell.execute_reply":"2024-06-06T08:54:09.054565Z"},"trusted":true},"execution_count":270,"outputs":[{"name":"stdout","text":"Số lượng mẫu trong tập train: 7542\nSố lượng mẫu trong tập validation: 942\nSố lượng mẫu trong tập test: 944\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:09.056399Z","iopub.execute_input":"2024-06-06T08:54:09.056667Z","iopub.status.idle":"2024-06-06T08:54:09.065810Z","shell.execute_reply.started":"2024-06-06T08:54:09.056633Z","shell.execute_reply":"2024-06-06T08:54:09.064976Z"},"trusted":true},"execution_count":271,"outputs":[{"execution_count":271,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?'}"},"metadata":{}}]},{"cell_type":"code","source":"en_nlp = English()\nvi_nlp = Vietnamese()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:09.070195Z","iopub.execute_input":"2024-06-06T08:54:09.070625Z","iopub.status.idle":"2024-06-06T08:54:09.282291Z","shell.execute_reply.started":"2024-06-06T08:54:09.070600Z","shell.execute_reply":"2024-06-06T08:54:09.281386Z"},"trusted":true},"execution_count":272,"outputs":[]},{"cell_type":"code","source":"string = \"What a lovely day it is today!\"\n[token.text for token in en_nlp.tokenizer(string)]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:09.283411Z","iopub.execute_input":"2024-06-06T08:54:09.283731Z","iopub.status.idle":"2024-06-06T08:54:09.290891Z","shell.execute_reply.started":"2024-06-06T08:54:09.283700Z","shell.execute_reply":"2024-06-06T08:54:09.290000Z"},"trusted":true},"execution_count":273,"outputs":[{"execution_count":273,"output_type":"execute_result","data":{"text/plain":"['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_example(example, en_nlp, vi_nlp, max_length, lower, sos_token, eos_token):\n    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n    vi_tokens = [token.text for token in vi_nlp.tokenizer(example[\"vi\"])][:max_length]\n    if lower:\n        en_tokens = [token.lower() for token in en_tokens]\n        vi_tokens = [token.lower() for token in vi_tokens]\n    en_tokens = [sos_token] + en_tokens + [eos_token]\n    vi_tokens = [sos_token] + vi_tokens + [eos_token]\n    example[\"en_tokens\"] = en_tokens\n    example[\"vi_tokens\"] = vi_tokens\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:09.291983Z","iopub.execute_input":"2024-06-06T08:54:09.292243Z","iopub.status.idle":"2024-06-06T08:54:09.300832Z","shell.execute_reply.started":"2024-06-06T08:54:09.292221Z","shell.execute_reply":"2024-06-06T08:54:09.299966Z"},"trusted":true},"execution_count":274,"outputs":[]},{"cell_type":"code","source":"max_length = 50\nlower = True\nsos_token = \"<sos>\"\neos_token = \"<eos>\"\n\nfn_kwargs = {\n    \"en_nlp\": en_nlp,\n    \"vi_nlp\": vi_nlp,\n    \"max_length\": max_length,\n    \"lower\": lower,\n    \"sos_token\": sos_token,\n    \"eos_token\": eos_token,\n}\ntrain_data = [tokenize_example(example, **fn_kwargs) for example in train_data]\nvalid_data = [tokenize_example(example, **fn_kwargs) for example in valid_data]\ntest_data = [tokenize_example(example, **fn_kwargs) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:09.302033Z","iopub.execute_input":"2024-06-06T08:54:09.302289Z","iopub.status.idle":"2024-06-06T08:54:12.589059Z","shell.execute_reply.started":"2024-06-06T08:54:09.302267Z","shell.execute_reply":"2024-06-06T08:54:12.588076Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.590288Z","iopub.execute_input":"2024-06-06T08:54:12.590585Z","iopub.status.idle":"2024-06-06T08:54:12.596784Z","shell.execute_reply.started":"2024-06-06T08:54:12.590560Z","shell.execute_reply":"2024-06-06T08:54:12.595843Z"},"trusted":true},"execution_count":276,"outputs":[{"execution_count":276,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?',\n 'en_tokens': ['<sos>',\n  'do',\n  'you',\n  'really',\n  'want',\n  'to',\n  'wear',\n  'that',\n  '?',\n  '<eos>'],\n 'vi_tokens': ['<sos>',\n  'bạn',\n  'thực sự',\n  'muốn',\n  'mặc',\n  'cái',\n  'đó',\n  'sao',\n  '?',\n  '<eos>']}"},"metadata":{}}]},{"cell_type":"code","source":"def yield_tokens(data,s):\n    for dct in data:\n        yield dct[s]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.597899Z","iopub.execute_input":"2024-06-06T08:54:12.598201Z","iopub.status.idle":"2024-06-06T08:54:12.607578Z","shell.execute_reply.started":"2024-06-06T08:54:12.598172Z","shell.execute_reply":"2024-06-06T08:54:12.606674Z"},"trusted":true},"execution_count":277,"outputs":[]},{"cell_type":"code","source":"min_freq = 2\nunk_token = \"<unk>\"\npad_token = \"<pad>\"\n\nspecial_tokens = [\n    unk_token,\n    pad_token,\n    sos_token,\n    eos_token,\n]\n\nen_vocab = torchtext.vocab.build_vocab_from_iterator(\n    yield_tokens(train_data,'en_tokens'),\n    min_freq=min_freq,\n    specials=special_tokens,\n)\n\nvi_vocab = torchtext.vocab.build_vocab_from_iterator(\n    yield_tokens(train_data,'vi_tokens'),\n    min_freq=min_freq,\n    specials=special_tokens,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.608515Z","iopub.execute_input":"2024-06-06T08:54:12.608763Z","iopub.status.idle":"2024-06-06T08:54:12.827590Z","shell.execute_reply.started":"2024-06-06T08:54:12.608742Z","shell.execute_reply":"2024-06-06T08:54:12.826594Z"},"trusted":true},"execution_count":278,"outputs":[]},{"cell_type":"code","source":"assert en_vocab[unk_token] == vi_vocab[unk_token]\nassert en_vocab[pad_token] == vi_vocab[pad_token]\n\nunk_index = en_vocab[unk_token]\npad_index = en_vocab[pad_token]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.829079Z","iopub.execute_input":"2024-06-06T08:54:12.829380Z","iopub.status.idle":"2024-06-06T08:54:12.834018Z","shell.execute_reply.started":"2024-06-06T08:54:12.829356Z","shell.execute_reply":"2024-06-06T08:54:12.833004Z"},"trusted":true},"execution_count":279,"outputs":[]},{"cell_type":"code","source":"en_vocab.set_default_index(unk_index)\nvi_vocab.set_default_index(unk_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.834969Z","iopub.execute_input":"2024-06-06T08:54:12.835231Z","iopub.status.idle":"2024-06-06T08:54:12.846102Z","shell.execute_reply.started":"2024-06-06T08:54:12.835209Z","shell.execute_reply":"2024-06-06T08:54:12.845164Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\nen_vocab.lookup_indices(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.847420Z","iopub.execute_input":"2024-06-06T08:54:12.847704Z","iopub.status.idle":"2024-06-06T08:54:12.858155Z","shell.execute_reply.started":"2024-06-06T08:54:12.847681Z","shell.execute_reply":"2024-06-06T08:54:12.857357Z"},"trusted":true},"execution_count":281,"outputs":[{"execution_count":281,"output_type":"execute_result","data":{"text/plain":"[5, 173, 509, 0, 0]"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.859265Z","iopub.execute_input":"2024-06-06T08:54:12.859593Z","iopub.status.idle":"2024-06-06T08:54:12.869323Z","shell.execute_reply.started":"2024-06-06T08:54:12.859561Z","shell.execute_reply":"2024-06-06T08:54:12.868437Z"},"trusted":true},"execution_count":282,"outputs":[{"execution_count":282,"output_type":"execute_result","data":{"text/plain":"['i', 'love', 'watching', '<unk>', '<unk>']"},"metadata":{}}]},{"cell_type":"code","source":"def numericalize_example(example, en_vocab, vi_vocab):\n    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n    vi_ids = vi_vocab.lookup_indices(example[\"vi_tokens\"])\n    example[\"en_ids\"] = en_ids\n    example[\"vi_ids\"] = vi_ids\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.870354Z","iopub.execute_input":"2024-06-06T08:54:12.870612Z","iopub.status.idle":"2024-06-06T08:54:12.879077Z","shell.execute_reply.started":"2024-06-06T08:54:12.870590Z","shell.execute_reply":"2024-06-06T08:54:12.878351Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"fn_kwargs = {\"en_vocab\": en_vocab, \"vi_vocab\": vi_vocab}\ntrain_data = [numericalize_example(example, **fn_kwargs) for example in train_data]\nvalid_data = [numericalize_example(example, **fn_kwargs) for example in valid_data]\ntest_data = [numericalize_example(example, **fn_kwargs) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.880134Z","iopub.execute_input":"2024-06-06T08:54:12.880390Z","iopub.status.idle":"2024-06-06T08:54:12.951725Z","shell.execute_reply.started":"2024-06-06T08:54:12.880368Z","shell.execute_reply":"2024-06-06T08:54:12.951048Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.952663Z","iopub.execute_input":"2024-06-06T08:54:12.952928Z","iopub.status.idle":"2024-06-06T08:54:12.959344Z","shell.execute_reply.started":"2024-06-06T08:54:12.952905Z","shell.execute_reply":"2024-06-06T08:54:12.958490Z"},"trusted":true},"execution_count":285,"outputs":[{"execution_count":285,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?',\n 'en_tokens': ['<sos>',\n  'do',\n  'you',\n  'really',\n  'want',\n  'to',\n  'wear',\n  'that',\n  '?',\n  '<eos>'],\n 'vi_tokens': ['<sos>',\n  'bạn',\n  'thực sự',\n  'muốn',\n  'mặc',\n  'cái',\n  'đó',\n  'sao',\n  '?',\n  '<eos>'],\n 'en_ids': [2, 14, 8, 88, 37, 6, 431, 15, 10, 3],\n 'vi_ids': [2, 8, 184, 30, 281, 34, 15, 97, 11, 3]}"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.lookup_tokens(train_data[0][\"en_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.960511Z","iopub.execute_input":"2024-06-06T08:54:12.960835Z","iopub.status.idle":"2024-06-06T08:54:12.971249Z","shell.execute_reply.started":"2024-06-06T08:54:12.960806Z","shell.execute_reply":"2024-06-06T08:54:12.970259Z"},"trusted":true},"execution_count":286,"outputs":[{"execution_count":286,"output_type":"execute_result","data":{"text/plain":"['<sos>', 'do', 'you', 'really', 'want', 'to', 'wear', 'that', '?', '<eos>']"},"metadata":{}}]},{"cell_type":"code","source":"def to_tensor(example):\n    example['en_ids'] = torch.tensor(np.array(example['en_ids']), dtype=torch.int64)\n    example['vi_ids'] = torch.tensor(np.array(example['vi_ids']), dtype=torch.int64)\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.972315Z","iopub.execute_input":"2024-06-06T08:54:12.972583Z","iopub.status.idle":"2024-06-06T08:54:12.980326Z","shell.execute_reply.started":"2024-06-06T08:54:12.972561Z","shell.execute_reply":"2024-06-06T08:54:12.979406Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"code","source":"train_data = [to_tensor(example) for example in train_data]\nvalid_data = [to_tensor(example) for example in valid_data]\ntest_data = [to_tensor(example) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:12.981427Z","iopub.execute_input":"2024-06-06T08:54:12.981677Z","iopub.status.idle":"2024-06-06T08:54:13.167903Z","shell.execute_reply.started":"2024-06-06T08:54:12.981655Z","shell.execute_reply":"2024-06-06T08:54:13.167222Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"def get_collate_fn(pad_index, max_length):\n    def collate_fn(batch):\n        batch_en_ids = []\n        batch_vi_ids = []\n#         batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n#         batch_vi_ids = nn.utils.rnn.pad_sequence(batch_vi_ids, padding_value=pad_index)\n        for example in batch:\n            en_ids = example[\"en_ids\"]\n            vi_ids = example[\"vi_ids\"]\n            if len(en_ids) > max_length:\n                en_ids = en_ids[:max_length]\n            else:\n                en_ids = torch.cat((en_ids, torch.tensor([pad_index] * (max_length - len(en_ids)))))\n            if len(vi_ids) > max_length:\n                vi_ids = vi_ids[:max_length]\n            else:\n                vi_ids = torch.cat((vi_ids, torch.tensor([pad_index] * (max_length - len(vi_ids)))))\n            assert len(en_ids) == max_length\n            assert len(vi_ids) == max_length\n            batch_en_ids.append(en_ids)\n            batch_vi_ids.append(vi_ids)\n        batch = {\n            \"en_ids\": torch.stack(batch_en_ids),\n            \"vi_ids\": torch.stack(batch_vi_ids),\n        }\n        return batch\n\n    return collate_fn","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:13.168987Z","iopub.execute_input":"2024-06-06T08:54:13.169299Z","iopub.status.idle":"2024-06-06T08:54:13.177878Z","shell.execute_reply.started":"2024-06-06T08:54:13.169267Z","shell.execute_reply":"2024-06-06T08:54:13.176998Z"},"trusted":true},"execution_count":289,"outputs":[]},{"cell_type":"code","source":"def get_data_loader(dataset, batch_size, pad_index, max_length, shuffle=False):\n    collate_fn = get_collate_fn(pad_index, max_length)\n    data_loader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        collate_fn=collate_fn,\n        shuffle=shuffle,\n    )\n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:13.184019Z","iopub.execute_input":"2024-06-06T08:54:13.184443Z","iopub.status.idle":"2024-06-06T08:54:13.191512Z","shell.execute_reply.started":"2024-06-06T08:54:13.184420Z","shell.execute_reply":"2024-06-06T08:54:13.190702Z"},"trusted":true},"execution_count":290,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nmax_length = 50\ntrain_data_loader = get_data_loader(train_data, batch_size, pad_index,max_length, shuffle=True)\nvalid_data_loader = get_data_loader(valid_data, batch_size, pad_index, max_length)\ntest_data_loader = get_data_loader(test_data, batch_size, pad_index, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:13.192353Z","iopub.execute_input":"2024-06-06T08:54:13.192576Z","iopub.status.idle":"2024-06-06T08:54:13.254604Z","shell.execute_reply.started":"2024-06-06T08:54:13.192556Z","shell.execute_reply":"2024-06-06T08:54:13.253725Z"},"trusted":true},"execution_count":291,"outputs":[]},{"cell_type":"code","source":"class TokenAndPositionEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_dim, max_length, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.word_emb = nn.Embedding(\n            num_embeddings=vocab_size,\n            embedding_dim=embed_dim)\n        self.pos_emb = nn.Embedding(\n            num_embeddings=max_length,\n            embedding_dim=embed_dim\n        )\n\n    def forward(self, x):\n        N, seq_len = x.size()\n        positions = torch.arange(0, seq_len).expand(N, seq_len).to(self.device)\n        output1 = self.word_emb(x)\n        output2 = self.pos_emb(positions)\n        output =  output1 + output2\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:13.255765Z","iopub.execute_input":"2024-06-06T08:54:13.256195Z","iopub.status.idle":"2024-06-06T08:54:13.263382Z","shell.execute_reply.started":"2024-06-06T08:54:13.256163Z","shell.execute_reply":"2024-06-06T08:54:13.262512Z"},"trusted":true},"execution_count":292,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoderBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            batch_first = True\n        )\n        self.ffn = nn.Sequential(\n            nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n        )\n        self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.dropout_1 = nn.Dropout(p=dropout)\n        self.dropout_2 = nn.Dropout(p=dropout)\n\n    def forward(self, query, key, value):\n        attn_output, _ = self.attn(query, key, value)\n        attn_output = self.dropout_1(attn_output)\n        out_1 = self.layernorm_1(query + attn_output)\n        ffn_output = self.ffn(out_1)\n        ffn_output = self.dropout_2(ffn_output)\n        out_2 = self.layernorm_2(out_1 + ffn_output)\n        return out_2","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:13.264416Z","iopub.execute_input":"2024-06-06T08:54:13.264735Z","iopub.status.idle":"2024-06-06T08:54:13.277742Z","shell.execute_reply.started":"2024-06-06T08:54:13.264702Z","shell.execute_reply":"2024-06-06T08:54:13.276810Z"},"trusted":true},"execution_count":293,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(nn.Module):\n    def __init__(self, src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.embedding = TokenAndPositionEmbedding(src_vocab_size, embed_dim, max_length, device)\n        self.layers = nn.ModuleList(\n            [\n                TransformerEncoderBlock(embed_dim, num_heads, ff_dim, dropout) for i in range(num_layers)\n            ]\n        )\n\n    def forward(self, x):\n        output = self.embedding(x)\n        for layer in self.layers:\n            output = layer(output, output, output)\n        return output\n     ","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:13.278703Z","iopub.execute_input":"2024-06-06T08:54:13.278992Z","iopub.status.idle":"2024-06-06T08:54:13.287996Z","shell.execute_reply.started":"2024-06-06T08:54:13.278942Z","shell.execute_reply":"2024-06-06T08:54:13.287133Z"},"trusted":true},"execution_count":294,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoderBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            batch_first = True\n        )\n        self.cross_attn = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            batch_first = True\n        )\n        self.ffn = nn.Sequential(\n            nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n        )\n        self.layernorm_1  = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.layernorm_2  = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.layernorm_3  = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.dropout_1 = nn.Dropout(p=dropout)\n        self.dropout_2 = nn.Dropout(p=dropout)\n        self.dropout_3 = nn.Dropout(p=dropout)\n\n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        attn_output, _ = self.attn(x, x, x, attn_mask=tgt_mask)\n        attn_output = self.dropout_1(attn_output)\n        out_1 = self.layernorm_1(x + attn_output)\n        attn_output, _ = self.cross_attn(out_1, enc_output, enc_output)\n        attn_output = self.dropout_2(attn_output)\n        out_2 = self.layernorm_2(out_1 + attn_output)\n        ffn_output = self.ffn(out_2)\n        ffn_output = self.dropout_3(ffn_output)\n        out_3 = self.layernorm_3(out_2 + ffn_output)\n        return out_3","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:13.288965Z","iopub.execute_input":"2024-06-06T08:54:13.289225Z","iopub.status.idle":"2024-06-06T08:54:13.302699Z","shell.execute_reply.started":"2024-06-06T08:54:13.289204Z","shell.execute_reply":"2024-06-06T08:54:13.301914Z"},"trusted":true},"execution_count":295,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoder(nn.Module):\n    def __init__(self, tgt_vocab_size, embed_dim, max_length, num_layers, num_aheads, ff_dim, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.embedding = TokenAndPositionEmbedding(tgt_vocab_size, embed_dim, max_length, device)\n        self.layers = nn.ModuleList(\n            [\n                TransformerDecoderBlock(embed_dim, num_heads, ff_dim, dropout) for i in range(num_layers)\n            ]\n        )\n\n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        output = self.embedding(x)\n        for layer in self.layers:\n            output = layer(output, enc_output, src_mask, tgt_mask)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:13.303722Z","iopub.execute_input":"2024-06-06T08:54:13.304005Z","iopub.status.idle":"2024-06-06T08:54:13.317147Z","shell.execute_reply.started":"2024-06-06T08:54:13.303978Z","shell.execute_reply":"2024-06-06T08:54:13.316434Z"},"trusted":true},"execution_count":296,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.encoder = TransformerEncoder(src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device)\n        self.decoder = TransformerDecoder(tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device)\n        self.fc = nn.Linear(embed_dim, tgt_vocab_size)\n\n    def generate_mask(self, src, tgt):\n        src_seq_len = src.shape[1]\n        tgt_seq_len = tgt.shape[1]\n\n        src_mask = torch.zeros((src_seq_len, src_seq_len), device=self.device).type(torch.bool)\n        tgt_mask = (torch.triu(torch.ones((tgt_seq_len, tgt_seq_len), device=self.device).type(torch.bool)) == 1).transpose(0,1)\n        tgt_mask = tgt_mask.float().masked_fill(tgt_mask == 0, float('-inf')).masked_fill(tgt_mask == 1, float(0.0))\n        return src_mask, tgt_mask\n\n    def forward(self, src, tgt):\n        src_mask, tgt_mask = self.generate_mask(src, tgt)\n        enc_output = self.encoder(src)\n        dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n        output = self.fc(dec_output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:54:13.318258Z","iopub.execute_input":"2024-06-06T08:54:13.318587Z","iopub.status.idle":"2024-06-06T08:54:13.331580Z","shell.execute_reply.started":"2024-06-06T08:54:13.318554Z","shell.execute_reply":"2024-06-06T08:54:13.330808Z"},"trusted":true},"execution_count":297,"outputs":[]},{"cell_type":"code","source":"src_vocab_size = len(en_vocab)\ntgt_vocab_size = len(vi_vocab)\nembed_dim = 128\nmax_length = 50\nnum_layers = 5\nnum_heads = 2\nff_dim = 256\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndropout = 0.3\nmodel = Transformer(src_vocab_size, tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:45:31.994636Z","iopub.execute_input":"2024-06-06T09:45:31.995195Z","iopub.status.idle":"2024-06-06T09:45:32.040632Z","shell.execute_reply.started":"2024-06-06T09:45:31.995163Z","shell.execute_reply":"2024-06-06T09:45:32.039875Z"},"trusted":true},"execution_count":376,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:45:32.544171Z","iopub.execute_input":"2024-06-06T09:45:32.544853Z","iopub.status.idle":"2024-06-06T09:45:32.550886Z","shell.execute_reply.started":"2024-06-06T09:45:32.544813Z","shell.execute_reply":"2024-06-06T09:45:32.549795Z"},"trusted":true},"execution_count":377,"outputs":[{"name":"stdout","text":"Transformer(\n  (encoder): TransformerEncoder(\n    (embedding): TokenAndPositionEmbedding(\n      (word_emb): Embedding(2187, 128)\n      (pos_emb): Embedding(50, 128)\n    )\n    (layers): ModuleList(\n      (0-4): 5 x TransformerEncoderBlock(\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (ffn): Sequential(\n          (0): Linear(in_features=128, out_features=256, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=256, out_features=128, bias=True)\n        )\n        (layernorm_1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (layernorm_2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (dropout_1): Dropout(p=0.3, inplace=False)\n        (dropout_2): Dropout(p=0.3, inplace=False)\n      )\n    )\n  )\n  (decoder): TransformerDecoder(\n    (embedding): TokenAndPositionEmbedding(\n      (word_emb): Embedding(2065, 128)\n      (pos_emb): Embedding(50, 128)\n    )\n    (layers): ModuleList(\n      (0-4): 5 x TransformerDecoderBlock(\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (cross_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n        )\n        (ffn): Sequential(\n          (0): Linear(in_features=128, out_features=256, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=256, out_features=128, bias=True)\n        )\n        (layernorm_1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (layernorm_2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (layernorm_3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (dropout_1): Dropout(p=0.3, inplace=False)\n        (dropout_2): Dropout(p=0.3, inplace=False)\n        (dropout_3): Dropout(p=0.3, inplace=False)\n      )\n    )\n  )\n  (fc): Linear(in_features=128, out_features=2065, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_fn(model, data_loader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(data_loader):\n        src = batch['en_ids'].to(device)\n        trg = batch['vi_ids'].to(device)\n        #src: n x src_seq_length\n        #trg: n x trg_seq_length\n        optimizer.zero_grad()\n        output = model(src, trg)\n        #output: n x trg_seq_length x trg_vocab_size\n        output_dim = output.shape[-1]\n        output = output[:,1:,].reshape(-1,output_dim)\n        #output: (n * trg_seq_length - 1) x trg_vocab_size\n        trg = trg[:,1:].reshape(-1)\n        #trg: n x trg_seq_length-1\n        loss = criterion(output, trg)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:45:33.181291Z","iopub.execute_input":"2024-06-06T09:45:33.181648Z","iopub.status.idle":"2024-06-06T09:45:33.189284Z","shell.execute_reply.started":"2024-06-06T09:45:33.181620Z","shell.execute_reply":"2024-06-06T09:45:33.188422Z"},"trusted":true},"execution_count":378,"outputs":[]},{"cell_type":"code","source":"def evaluate_fn(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for i, batch in enumerate(data_loader):\n            src = batch['en_ids'].to(device)\n            trg = batch['vi_ids'].to(device)\n            #src: n x src_seq_length\n            #trg: n x trg_seq_length\n            output = model(src, trg)\n            output_dim = output.shape[-1]\n            output = output[:,1:,].reshape(-1,output_dim)\n            #output: n x trg_seq_legth - 1 x trg_vocab_size\n            trg = trg[:,1:].reshape(-1)\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:45:33.903633Z","iopub.execute_input":"2024-06-06T09:45:33.904513Z","iopub.status.idle":"2024-06-06T09:45:33.915332Z","shell.execute_reply.started":"2024-06-06T09:45:33.904473Z","shell.execute_reply":"2024-06-06T09:45:33.914293Z"},"trusted":true},"execution_count":379,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:45:34.432646Z","iopub.execute_input":"2024-06-06T09:45:34.433446Z","iopub.status.idle":"2024-06-06T09:45:34.439887Z","shell.execute_reply.started":"2024-06-06T09:45:34.433413Z","shell.execute_reply":"2024-06-06T09:45:34.439016Z"},"trusted":true},"execution_count":380,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\nbest_valid_loss = float(\"inf\")\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    train_loss = train_fn(\n        model,\n        train_data_loader,\n        optimizer,\n        criterion,\n        device,\n    )\n    valid_loss = evaluate_fn(\n        model,\n        valid_data_loader,\n        criterion,\n        device,\n    )\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), \"model.pt\")\n    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:45:39.220515Z","iopub.execute_input":"2024-06-06T09:45:39.221308Z","iopub.status.idle":"2024-06-06T09:46:45.508508Z","shell.execute_reply.started":"2024-06-06T09:45:39.221266Z","shell.execute_reply":"2024-06-06T09:46:45.507579Z"},"trusted":true},"execution_count":381,"outputs":[{"name":"stderr","text":"  5%|▌         | 1/20 [00:03<01:03,  3.34s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.738 | Train PPL:  41.994\n\tValid Loss:   1.516 | Valid PPL:   4.556\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 2/20 [00:06<00:59,  3.32s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.173 | Train PPL:   3.232\n\tValid Loss:   0.611 | Valid PPL:   1.843\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 3/20 [00:09<00:56,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.570 | Train PPL:   1.769\n\tValid Loss:   0.320 | Valid PPL:   1.377\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 4/20 [00:13<00:53,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.326 | Train PPL:   1.385\n\tValid Loss:   0.182 | Valid PPL:   1.200\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 5/20 [00:16<00:49,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.195 | Train PPL:   1.215\n\tValid Loss:   0.106 | Valid PPL:   1.112\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 6/20 [00:19<00:46,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.118 | Train PPL:   1.125\n\tValid Loss:   0.059 | Valid PPL:   1.061\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 7/20 [00:23<00:43,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.071 | Train PPL:   1.073\n\tValid Loss:   0.034 | Valid PPL:   1.035\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 8/20 [00:26<00:39,  3.32s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.042 | Train PPL:   1.043\n\tValid Loss:   0.019 | Valid PPL:   1.020\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 9/20 [00:29<00:36,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.026 | Train PPL:   1.026\n\tValid Loss:   0.012 | Valid PPL:   1.012\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 10/20 [00:33<00:33,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.017 | Train PPL:   1.017\n\tValid Loss:   0.008 | Valid PPL:   1.008\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 11/20 [00:36<00:29,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.012 | Train PPL:   1.012\n\tValid Loss:   0.006 | Valid PPL:   1.006\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 12/20 [00:39<00:26,  3.30s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.010 | Train PPL:   1.010\n\tValid Loss:   0.005 | Valid PPL:   1.005\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 13/20 [00:43<00:23,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.008 | Train PPL:   1.008\n\tValid Loss:   0.004 | Valid PPL:   1.004\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 14/20 [00:46<00:19,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.006 | Train PPL:   1.006\n\tValid Loss:   0.003 | Valid PPL:   1.003\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 15/20 [00:49<00:16,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.005 | Train PPL:   1.005\n\tValid Loss:   0.003 | Valid PPL:   1.003\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 16/20 [00:52<00:13,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.005 | Train PPL:   1.005\n\tValid Loss:   0.002 | Valid PPL:   1.002\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 17/20 [00:56<00:09,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.004 | Train PPL:   1.004\n\tValid Loss:   0.002 | Valid PPL:   1.002\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 18/20 [00:59<00:06,  3.32s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.004 | Train PPL:   1.004\n\tValid Loss:   0.002 | Valid PPL:   1.002\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 19/20 [01:02<00:03,  3.33s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.003 | Train PPL:   1.003\n\tValid Loss:   0.002 | Valid PPL:   1.002\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20/20 [01:06<00:00,  3.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.003 | Train PPL:   1.003\n\tValid Loss:   0.001 | Valid PPL:   1.001\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"model.pt\"))\ntest_loss = evaluate_fn(model, test_data_loader, criterion, device)\nprint(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:46:45.510253Z","iopub.execute_input":"2024-06-06T09:46:45.510557Z","iopub.status.idle":"2024-06-06T09:46:45.702335Z","shell.execute_reply.started":"2024-06-06T09:46:45.510531Z","shell.execute_reply":"2024-06-06T09:46:45.701258Z"},"trusted":true},"execution_count":382,"outputs":[{"name":"stdout","text":"| Test Loss: 0.001 | Test PPL:   1.001 |\n","output_type":"stream"}]},{"cell_type":"code","source":"def translate_sentence(\n    sentence,\n    model,\n    en_nlp,\n    de_nlp,\n    en_vocab,\n    de_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n    max_output_length=20,\n):\n    model.eval()\n    with torch.no_grad():\n        if isinstance(sentence, str):\n            tokens = [token.text for token in en_nlp.tokenizer(sentence)]\n        else:\n            tokens = [token for token in sentence]\n        if lower:\n            tokens = [token.lower() for token in tokens]\n        res = []\n        tokens = [sos_token] + tokens + [eos_token]\n        ids = en_vocab.lookup_indices(tokens)\n        print(ids)\n        src = torch.LongTensor(ids).unsqueeze(0).to(device)\n        encoder_output = model.encoder(src)\n        tgt = torch.LongTensor(de_vocab.lookup_indices([sos_token])).unsqueeze(0).to(device)\n        for i in range(max_output_length):\n            src_mask,tgt_mask = model.generate_mask(src, tgt)\n            decoder_output = model.decoder(tgt,encoder_output,src_mask,tgt_mask)\n            predicted_token = decoder_output[0,i].argmax(-1).item()\n            res.append(predicted_token)\n            tgt = torch.cat((tgt, torch.tensor([[predicted_token]]).to(device)), dim=1)\n            if predicted_token == en_vocab[eos_token]:\n                break\n        output = tgt[0].cpu().numpy()\n#         output = model(src,torch.tensor(res).unsqueeze(0).to(device))\n#         output = output[0].argmax(-1).squeeze().detach().cpu().numpy()\n        tokens = de_vocab.lookup_tokens(output)\n    return \" \".join(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:46:45.703512Z","iopub.execute_input":"2024-06-06T09:46:45.703763Z","iopub.status.idle":"2024-06-06T09:46:45.714688Z","shell.execute_reply.started":"2024-06-06T09:46:45.703740Z","shell.execute_reply":"2024-06-06T09:46:45.713854Z"},"trusted":true},"execution_count":383,"outputs":[]},{"cell_type":"code","source":"sentence = train_data[35]['en']\nprint(sentence)\ntranslate_sentence(\n    sentence,\n    model,\n    en_nlp,\n    vi_nlp,\n    en_vocab,\n    vi_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:46:45.716429Z","iopub.execute_input":"2024-06-06T09:46:45.716702Z","iopub.status.idle":"2024-06-06T09:46:45.841652Z","shell.execute_reply.started":"2024-06-06T09:46:45.716680Z","shell.execute_reply":"2024-06-06T09:46:45.840814Z"},"trusted":true},"execution_count":384,"outputs":[{"name":"stdout","text":"Tom is almost never wrong.\n[2, 7, 13, 413, 87, 268, 4, 3]\n","output_type":"stream"},{"execution_count":384,"output_type":"execute_result","data":{"text/plain":"'<sos> không thể không thể không thể không thể không thể không thể không thể không thể không thể không thể không thể không thể không thể không thể không thể không thể không thể không thể đã để'"},"metadata":{}}]}]}
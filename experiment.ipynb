{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8537196,"sourceType":"datasetVersion","datasetId":5099533}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyvi torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:16.050115Z","iopub.execute_input":"2024-06-05T18:34:16.050468Z","iopub.status.idle":"2024-06-05T18:34:32.152174Z","shell.execute_reply.started":"2024-06-05T18:34:16.050442Z","shell.execute_reply":"2024-06-05T18:34:32.151189Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.2.0)\nCollecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.66.4)\nDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nDownloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\nDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchsummary, python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.3.6 torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nimport numpy as np\nimport spacy\nimport torchtext\nimport tqdm\nimport random\nfrom spacy.lang.vi import Vietnamese\nfrom spacy.lang.en import English\nfrom torch.utils.data import Dataset, random_split\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:32.154262Z","iopub.execute_input":"2024-06-05T18:34:32.154604Z","iopub.status.idle":"2024-06-05T18:34:40.624152Z","shell.execute_reply.started":"2024-06-05T18:34:32.154576Z","shell.execute_reply":"2024-06-05T18:34:40.623197Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"seed = 1234\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:40.625354Z","iopub.execute_input":"2024-06-05T18:34:40.625963Z","iopub.status.idle":"2024-06-05T18:34:40.634550Z","shell.execute_reply.started":"2024-06-05T18:34:40.625933Z","shell.execute_reply":"2024-06-05T18:34:40.633483Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def load_data(path):\n    data = []\n    with open(path,'r') as file:\n        for line in file.readlines():\n            splitted_line = line.split('\\t')\n            eng = splitted_line[0]\n            vi = splitted_line[1]\n            data.append({'vi':vi, \n                         'en':eng})\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:40.637603Z","iopub.execute_input":"2024-06-05T18:34:40.638248Z","iopub.status.idle":"2024-06-05T18:34:40.718524Z","shell.execute_reply.started":"2024-06-05T18:34:40.638221Z","shell.execute_reply":"2024-06-05T18:34:40.717560Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, index):\n        return self.data[index]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:40.720009Z","iopub.execute_input":"2024-06-05T18:34:40.720714Z","iopub.status.idle":"2024-06-05T18:34:40.729182Z","shell.execute_reply.started":"2024-06-05T18:34:40.720676Z","shell.execute_reply":"2024-06-05T18:34:40.728284Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset = CustomDataset(load_data('/kaggle/input/languagedata/data/vie.txt'))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:40.730409Z","iopub.execute_input":"2024-06-05T18:34:40.730827Z","iopub.status.idle":"2024-06-05T18:34:40.780318Z","shell.execute_reply.started":"2024-06-05T18:34:40.730741Z","shell.execute_reply":"2024-06-05T18:34:40.779516Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#7:2:1\ntotal_samples = len(dataset)\ntrain_size = int(0.8 * total_samples)\nval_size = int(0.1 * total_samples)\ntest_size = total_samples - train_size - val_size","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:40.781558Z","iopub.execute_input":"2024-06-05T18:34:40.781913Z","iopub.status.idle":"2024-06-05T18:34:40.786574Z","shell.execute_reply.started":"2024-06-05T18:34:40.781884Z","shell.execute_reply":"2024-06-05T18:34:40.785630Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data, valid_data, test_data = random_split(dataset, [train_size, val_size, test_size])\nprint(\"Số lượng mẫu trong tập train:\", len(train_data))\nprint(\"Số lượng mẫu trong tập validation:\", len(valid_data))\nprint(\"Số lượng mẫu trong tập test:\", len(test_data))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:40.787704Z","iopub.execute_input":"2024-06-05T18:34:40.788028Z","iopub.status.idle":"2024-06-05T18:34:40.816331Z","shell.execute_reply.started":"2024-06-05T18:34:40.788005Z","shell.execute_reply":"2024-06-05T18:34:40.815344Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Số lượng mẫu trong tập train: 7542\nSố lượng mẫu trong tập validation: 942\nSố lượng mẫu trong tập test: 944\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:40.817455Z","iopub.execute_input":"2024-06-05T18:34:40.817749Z","iopub.status.idle":"2024-06-05T18:34:40.824648Z","shell.execute_reply.started":"2024-06-05T18:34:40.817724Z","shell.execute_reply":"2024-06-05T18:34:40.823753Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?'}"},"metadata":{}}]},{"cell_type":"code","source":"en_nlp = English()\nvi_nlp = Vietnamese()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:40.829315Z","iopub.execute_input":"2024-06-05T18:34:40.829706Z","iopub.status.idle":"2024-06-05T18:34:41.555442Z","shell.execute_reply.started":"2024-06-05T18:34:40.829682Z","shell.execute_reply":"2024-06-05T18:34:41.554425Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"string = \"What a lovely day it is today!\"\n[token.text for token in en_nlp.tokenizer(string)]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:41.556723Z","iopub.execute_input":"2024-06-05T18:34:41.557119Z","iopub.status.idle":"2024-06-05T18:34:41.565108Z","shell.execute_reply.started":"2024-06-05T18:34:41.557085Z","shell.execute_reply":"2024-06-05T18:34:41.564068Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_example(example, en_nlp, vi_nlp, max_length, lower, sos_token, eos_token):\n    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n    vi_tokens = [token.text for token in vi_nlp.tokenizer(example[\"vi\"])][:max_length]\n    if lower:\n        en_tokens = [token.lower() for token in en_tokens]\n        vi_tokens = [token.lower() for token in vi_tokens]\n    en_tokens = [sos_token] + en_tokens + [eos_token]\n    vi_tokens = [sos_token] + vi_tokens + [eos_token]\n    example[\"en_tokens\"] = en_tokens\n    example[\"vi_tokens\"] = vi_tokens\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:41.566297Z","iopub.execute_input":"2024-06-05T18:34:41.566573Z","iopub.status.idle":"2024-06-05T18:34:41.577383Z","shell.execute_reply.started":"2024-06-05T18:34:41.566550Z","shell.execute_reply":"2024-06-05T18:34:41.576408Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"max_length = 50\nlower = True\nsos_token = \"<sos>\"\neos_token = \"<eos>\"\n\nfn_kwargs = {\n    \"en_nlp\": en_nlp,\n    \"vi_nlp\": vi_nlp,\n    \"max_length\": max_length,\n    \"lower\": lower,\n    \"sos_token\": sos_token,\n    \"eos_token\": eos_token,\n}\ntrain_data = [tokenize_example(example, **fn_kwargs) for example in train_data]\nvalid_data = [tokenize_example(example, **fn_kwargs) for example in valid_data]\ntest_data = [tokenize_example(example, **fn_kwargs) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:41.578618Z","iopub.execute_input":"2024-06-05T18:34:41.579611Z","iopub.status.idle":"2024-06-05T18:34:45.268737Z","shell.execute_reply.started":"2024-06-05T18:34:41.579577Z","shell.execute_reply":"2024-06-05T18:34:45.267913Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.270060Z","iopub.execute_input":"2024-06-05T18:34:45.270447Z","iopub.status.idle":"2024-06-05T18:34:45.278127Z","shell.execute_reply.started":"2024-06-05T18:34:45.270412Z","shell.execute_reply":"2024-06-05T18:34:45.277205Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?',\n 'en_tokens': ['<sos>',\n  'do',\n  'you',\n  'really',\n  'want',\n  'to',\n  'wear',\n  'that',\n  '?',\n  '<eos>'],\n 'vi_tokens': ['<sos>',\n  'bạn',\n  'thực sự',\n  'muốn',\n  'mặc',\n  'cái',\n  'đó',\n  'sao',\n  '?',\n  '<eos>']}"},"metadata":{}}]},{"cell_type":"code","source":"def yield_tokens(data,s):\n    for dct in data:\n        yield dct[s]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.279588Z","iopub.execute_input":"2024-06-05T18:34:45.280281Z","iopub.status.idle":"2024-06-05T18:34:45.289076Z","shell.execute_reply.started":"2024-06-05T18:34:45.280239Z","shell.execute_reply":"2024-06-05T18:34:45.288172Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"min_freq = 2\nunk_token = \"<unk>\"\npad_token = \"<pad>\"\n\nspecial_tokens = [\n    unk_token,\n    pad_token,\n    sos_token,\n    eos_token,\n]\n\nen_vocab = torchtext.vocab.build_vocab_from_iterator(\n    yield_tokens(train_data,'en_tokens'),\n    min_freq=min_freq,\n    specials=special_tokens,\n)\n\nvi_vocab = torchtext.vocab.build_vocab_from_iterator(\n    yield_tokens(train_data,'vi_tokens'),\n    min_freq=min_freq,\n    specials=special_tokens,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.290170Z","iopub.execute_input":"2024-06-05T18:34:45.290443Z","iopub.status.idle":"2024-06-05T18:34:45.726363Z","shell.execute_reply.started":"2024-06-05T18:34:45.290419Z","shell.execute_reply":"2024-06-05T18:34:45.725274Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"assert en_vocab[unk_token] == vi_vocab[unk_token]\nassert en_vocab[pad_token] == vi_vocab[pad_token]\n\nunk_index = en_vocab[unk_token]\npad_index = en_vocab[pad_token]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.728065Z","iopub.execute_input":"2024-06-05T18:34:45.728397Z","iopub.status.idle":"2024-06-05T18:34:45.734508Z","shell.execute_reply.started":"2024-06-05T18:34:45.728372Z","shell.execute_reply":"2024-06-05T18:34:45.733618Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"en_vocab.set_default_index(unk_index)\nvi_vocab.set_default_index(unk_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.735842Z","iopub.execute_input":"2024-06-05T18:34:45.736143Z","iopub.status.idle":"2024-06-05T18:34:45.744698Z","shell.execute_reply.started":"2024-06-05T18:34:45.736118Z","shell.execute_reply":"2024-06-05T18:34:45.743663Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\nen_vocab.lookup_indices(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.745699Z","iopub.execute_input":"2024-06-05T18:34:45.745997Z","iopub.status.idle":"2024-06-05T18:34:45.757555Z","shell.execute_reply.started":"2024-06-05T18:34:45.745973Z","shell.execute_reply":"2024-06-05T18:34:45.756634Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[5, 173, 509, 0, 0]"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.758657Z","iopub.execute_input":"2024-06-05T18:34:45.758952Z","iopub.status.idle":"2024-06-05T18:34:45.769747Z","shell.execute_reply.started":"2024-06-05T18:34:45.758928Z","shell.execute_reply":"2024-06-05T18:34:45.768799Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"['i', 'love', 'watching', '<unk>', '<unk>']"},"metadata":{}}]},{"cell_type":"code","source":"def numericalize_example(example, en_vocab, vi_vocab):\n    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n    vi_ids = vi_vocab.lookup_indices(example[\"vi_tokens\"])\n    example[\"en_ids\"] = en_ids\n    example[\"vi_ids\"] = vi_ids\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.771081Z","iopub.execute_input":"2024-06-05T18:34:45.771457Z","iopub.status.idle":"2024-06-05T18:34:45.778660Z","shell.execute_reply.started":"2024-06-05T18:34:45.771424Z","shell.execute_reply":"2024-06-05T18:34:45.777807Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"fn_kwargs = {\"en_vocab\": en_vocab, \"vi_vocab\": vi_vocab}\ntrain_data = [numericalize_example(example, **fn_kwargs) for example in train_data]\nvalid_data = [numericalize_example(example, **fn_kwargs) for example in valid_data]\ntest_data = [numericalize_example(example, **fn_kwargs) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.779902Z","iopub.execute_input":"2024-06-05T18:34:45.780215Z","iopub.status.idle":"2024-06-05T18:34:45.862586Z","shell.execute_reply.started":"2024-06-05T18:34:45.780191Z","shell.execute_reply":"2024-06-05T18:34:45.861778Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.863918Z","iopub.execute_input":"2024-06-05T18:34:45.864285Z","iopub.status.idle":"2024-06-05T18:34:45.872351Z","shell.execute_reply.started":"2024-06-05T18:34:45.864251Z","shell.execute_reply":"2024-06-05T18:34:45.871418Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?',\n 'en_tokens': ['<sos>',\n  'do',\n  'you',\n  'really',\n  'want',\n  'to',\n  'wear',\n  'that',\n  '?',\n  '<eos>'],\n 'vi_tokens': ['<sos>',\n  'bạn',\n  'thực sự',\n  'muốn',\n  'mặc',\n  'cái',\n  'đó',\n  'sao',\n  '?',\n  '<eos>'],\n 'en_ids': [2, 14, 8, 88, 37, 6, 431, 15, 10, 3],\n 'vi_ids': [2, 8, 184, 30, 281, 34, 15, 97, 11, 3]}"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.lookup_tokens(train_data[0][\"en_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.873565Z","iopub.execute_input":"2024-06-05T18:34:45.873905Z","iopub.status.idle":"2024-06-05T18:34:45.884531Z","shell.execute_reply.started":"2024-06-05T18:34:45.873879Z","shell.execute_reply":"2024-06-05T18:34:45.883485Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"['<sos>', 'do', 'you', 'really', 'want', 'to', 'wear', 'that', '?', '<eos>']"},"metadata":{}}]},{"cell_type":"code","source":"def to_tensor(example):\n    example['en_ids'] = torch.tensor(np.array(example['en_ids']), dtype=torch.int64)\n    example['vi_ids'] = torch.tensor(np.array(example['vi_ids']), dtype=torch.int64)\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.885578Z","iopub.execute_input":"2024-06-05T18:34:45.885897Z","iopub.status.idle":"2024-06-05T18:34:45.893497Z","shell.execute_reply.started":"2024-06-05T18:34:45.885871Z","shell.execute_reply":"2024-06-05T18:34:45.892585Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_data = [to_tensor(example) for example in train_data]\nvalid_data = [to_tensor(example) for example in valid_data]\ntest_data = [to_tensor(example) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:45.894663Z","iopub.execute_input":"2024-06-05T18:34:45.895557Z","iopub.status.idle":"2024-06-05T18:34:46.158711Z","shell.execute_reply.started":"2024-06-05T18:34:45.895480Z","shell.execute_reply":"2024-06-05T18:34:46.157741Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def get_collate_fn(pad_index):\n    def collate_fn(batch):\n        batch_en_ids = [example[\"en_ids\"] for example in batch]\n        batch_vi_ids = [example[\"vi_ids\"] for example in batch]\n        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n        batch_vi_ids = nn.utils.rnn.pad_sequence(batch_vi_ids, padding_value=pad_index)\n        batch = {\n            \"en_ids\": batch_en_ids.T,\n            \"vi_ids\": batch_vi_ids.T,\n        }\n        return batch\n\n    return collate_fn","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.160267Z","iopub.execute_input":"2024-06-05T18:34:46.160607Z","iopub.status.idle":"2024-06-05T18:34:46.167931Z","shell.execute_reply.started":"2024-06-05T18:34:46.160579Z","shell.execute_reply":"2024-06-05T18:34:46.166861Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n    collate_fn = get_collate_fn(pad_index)\n    data_loader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        collate_fn=collate_fn,\n        shuffle=shuffle,\n    )\n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.174162Z","iopub.execute_input":"2024-06-05T18:34:46.174501Z","iopub.status.idle":"2024-06-05T18:34:46.180170Z","shell.execute_reply.started":"2024-06-05T18:34:46.174475Z","shell.execute_reply":"2024-06-05T18:34:46.179190Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\ntrain_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\nvalid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\ntest_data_loader = get_data_loader(test_data, batch_size, pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.181566Z","iopub.execute_input":"2024-06-05T18:34:46.181942Z","iopub.status.idle":"2024-06-05T18:34:46.196038Z","shell.execute_reply.started":"2024-06-05T18:34:46.181904Z","shell.execute_reply":"2024-06-05T18:34:46.195153Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class TokenAndPositionEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_dim, max_length, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.word_emb = nn.Embedding(\n            num_embeddings=vocab_size,\n            embedding_dim=embed_dim)\n        self.pos_emb = nn.Embedding(\n            num_embeddings=max_length,\n            embedding_dim=embed_dim\n        )\n\n    def forward(self, x):\n        N, seq_len = x.size()\n        positions = torch.arange(0, seq_len).expand(N, seq_len).to(self.device)\n        output1 = self.word_emb(x)\n        output2 = self.pos_emb(positions)\n        output =  output1 + output2\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.197309Z","iopub.execute_input":"2024-06-05T18:34:46.198134Z","iopub.status.idle":"2024-06-05T18:34:46.212103Z","shell.execute_reply.started":"2024-06-05T18:34:46.198096Z","shell.execute_reply":"2024-06-05T18:34:46.211183Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoderBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            batch_first = True\n        )\n        self.ffn = nn.Sequential(\n            nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n        )\n        self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.dropout_1 = nn.Dropout(p=dropout)\n        self.dropout_2 = nn.Dropout(p=dropout)\n\n    def forward(self, query, key, value):\n        attn_output, _ = self.attn(query, key, value)\n        attn_output = self.dropout_1(attn_output)\n        out_1 = self.layernorm_1(query + attn_output)\n        ffn_output = self.ffn(out_1)\n        ffn_output = self.dropout_2(ffn_output)\n        out_2 = self.layernorm_2(out_1 + ffn_output)\n        return out_2","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.213294Z","iopub.execute_input":"2024-06-05T18:34:46.213593Z","iopub.status.idle":"2024-06-05T18:34:46.225929Z","shell.execute_reply.started":"2024-06-05T18:34:46.213567Z","shell.execute_reply":"2024-06-05T18:34:46.224833Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(nn.Module):\n    def __init__(self, src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.embedding = TokenAndPositionEmbedding(src_vocab_size, embed_dim, max_length, device)\n        self.layers = nn.ModuleList(\n            [\n                TransformerEncoderBlock(embed_dim, num_heads, ff_dim, dropout) for i in range(num_layers)\n            ]\n        )\n\n    def forward(self, x):\n        output = self.embedding(x)\n        for layer in self.layers:\n            output = layer(output, output, output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.227196Z","iopub.execute_input":"2024-06-05T18:34:46.227552Z","iopub.status.idle":"2024-06-05T18:34:46.240336Z","shell.execute_reply.started":"2024-06-05T18:34:46.227525Z","shell.execute_reply":"2024-06-05T18:34:46.239405Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoderBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            batch_first = True\n        )\n        self.cross_attn = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            batch_first = True\n        )\n        self.ffn = nn.Sequential(\n            nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n        )\n        self.layernorm_1  = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.layernorm_2  = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.layernorm_3  = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.dropout_1 = nn.Dropout(p=dropout)\n        self.dropout_2 = nn.Dropout(p=dropout)\n        self.dropout_3 = nn.Dropout(p=dropout)\n\n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        attn_output, _ = self.attn(x, x, x, attn_mask=tgt_mask)\n        attn_output = self.dropout_1(attn_output)\n        out_1 = self.layernorm_1(x + attn_output)\n        attn_output, _ = self.cross_attn(out_1, enc_output, enc_output)\n        attn_output = self.dropout_2(attn_output)\n        out_2 = self.layernorm_2(out_1 + attn_output)\n        ffn_output = self.ffn(out_2)\n        ffn_output = self.dropout_3(ffn_output)\n        out_3 = self.layernorm_3(out_2 + ffn_output)\n        return out_3","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.241492Z","iopub.execute_input":"2024-06-05T18:34:46.241852Z","iopub.status.idle":"2024-06-05T18:34:46.254048Z","shell.execute_reply.started":"2024-06-05T18:34:46.241825Z","shell.execute_reply":"2024-06-05T18:34:46.253128Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoder(nn.Module):\n    def __init__(self, tgt_vocab_size, embed_dim, max_length, num_layers, num_aheads, ff_dim, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.embedding = TokenAndPositionEmbedding(tgt_vocab_size, embed_dim, max_length, device)\n        self.layers = nn.ModuleList(\n            [\n                TransformerDecoderBlock(embed_dim, num_heads, ff_dim, dropout) for i in range(num_layers)\n            ]\n        )\n\n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        output = self.embedding(x)\n        for layer in self.layers:\n            output = layer(output, enc_output, src_mask, tgt_mask)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.255302Z","iopub.execute_input":"2024-06-05T18:34:46.255946Z","iopub.status.idle":"2024-06-05T18:34:46.268794Z","shell.execute_reply.started":"2024-06-05T18:34:46.255918Z","shell.execute_reply":"2024-06-05T18:34:46.267816Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.encoder = TransformerEncoder(src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device)\n        self.decoder = TransformerDecoder(tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device)\n        self.fc = nn.Linear(embed_dim, tgt_vocab_size)\n\n    def generate_mask(self, src, tgt):\n        src_seq_len = src.shape[1]\n        tgt_seq_len = tgt.shape[1]\n\n        src_mask = torch.zeros((src_seq_len, src_seq_len), device=self.device).type(torch.bool)\n        tgt_mask = (torch.triu(torch.ones((tgt_seq_len, tgt_seq_len), device=self.device).type(torch.bool)) == 1).transpose(0,1)\n        tgt_mask = tgt_mask.float().masked_fill(tgt_mask == 0, float('-inf')).masked_fill(tgt_mask == 1, float(0.0))\n        return src_mask, tgt_mask\n\n    def forward(self, src, tgt):\n        src_mask, tgt_mask = self.generate_mask(src, tgt)\n        enc_output = self.encoder(src)\n        dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n        output = self.fc(dec_output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.270232Z","iopub.execute_input":"2024-06-05T18:34:46.271128Z","iopub.status.idle":"2024-06-05T18:34:46.283831Z","shell.execute_reply.started":"2024-06-05T18:34:46.271100Z","shell.execute_reply":"2024-06-05T18:34:46.282811Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"src_vocab_size = len(en_vocab)\ntgt_vocab_size = len(vi_vocab)\nembed_dim = 300\nmax_length = 50\nnum_layers = 5\nnum_heads = 5\nff_dim = 512\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndropout = 0.5\nmodel = Transformer(src_vocab_size, tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.284904Z","iopub.execute_input":"2024-06-05T18:34:46.285170Z","iopub.status.idle":"2024-06-05T18:34:46.602144Z","shell.execute_reply.started":"2024-06-05T18:34:46.285147Z","shell.execute_reply":"2024-06-05T18:34:46.601195Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.603669Z","iopub.execute_input":"2024-06-05T18:34:46.604123Z","iopub.status.idle":"2024-06-05T18:34:46.610895Z","shell.execute_reply.started":"2024-06-05T18:34:46.604071Z","shell.execute_reply":"2024-06-05T18:34:46.609816Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Transformer(\n  (encoder): TransformerEncoder(\n    (embedding): TokenAndPositionEmbedding(\n      (word_emb): Embedding(2187, 300)\n      (pos_emb): Embedding(50, 300)\n    )\n    (layers): ModuleList(\n      (0-4): 5 x TransformerEncoderBlock(\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n        )\n        (ffn): Sequential(\n          (0): Linear(in_features=300, out_features=512, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=512, out_features=300, bias=True)\n        )\n        (layernorm_1): LayerNorm((300,), eps=1e-06, elementwise_affine=True)\n        (layernorm_2): LayerNorm((300,), eps=1e-06, elementwise_affine=True)\n        (dropout_1): Dropout(p=0.5, inplace=False)\n        (dropout_2): Dropout(p=0.5, inplace=False)\n      )\n    )\n  )\n  (decoder): TransformerDecoder(\n    (embedding): TokenAndPositionEmbedding(\n      (word_emb): Embedding(2065, 300)\n      (pos_emb): Embedding(50, 300)\n    )\n    (layers): ModuleList(\n      (0-4): 5 x TransformerDecoderBlock(\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n        )\n        (cross_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n        )\n        (ffn): Sequential(\n          (0): Linear(in_features=300, out_features=512, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=512, out_features=300, bias=True)\n        )\n        (layernorm_1): LayerNorm((300,), eps=1e-06, elementwise_affine=True)\n        (layernorm_2): LayerNorm((300,), eps=1e-06, elementwise_affine=True)\n        (layernorm_3): LayerNorm((300,), eps=1e-06, elementwise_affine=True)\n        (dropout_1): Dropout(p=0.5, inplace=False)\n        (dropout_2): Dropout(p=0.5, inplace=False)\n        (dropout_3): Dropout(p=0.5, inplace=False)\n      )\n    )\n  )\n  (fc): Linear(in_features=300, out_features=2065, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_fn(model, data_loader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(data_loader):\n        src = batch['en_ids'].to(device)\n        trg = batch['vi_ids'].to(device)\n        #src: n x src_seq_length\n        #trg: n x trg_seq_length\n        optimizer.zero_grad()\n        output = model(src, trg)\n        #output: n x trg_seq_length x trg_vocab_size\n        output_dim = output.shape[-1]\n        output = output[:,1:,].reshape(-1,output_dim)\n        #output: (n * trg_seq_length - 1) x trg_vocab_size\n        trg = trg[:,1:].reshape(-1)\n        #trg: n x trg_seq_length-1\n        loss = criterion(output, trg)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.612837Z","iopub.execute_input":"2024-06-05T18:34:46.613175Z","iopub.status.idle":"2024-06-05T18:34:46.621796Z","shell.execute_reply.started":"2024-06-05T18:34:46.613150Z","shell.execute_reply":"2024-06-05T18:34:46.620825Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def evaluate_fn(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for i, batch in enumerate(data_loader):\n            src = batch['en_ids'].to(device)\n            trg = batch['vi_ids'].to(device)\n            #src: n x src_seq_length\n            #trg: n x trg_seq_length\n            output = model(src, trg)\n            output_dim = output.shape[-1]\n            output = output[:,1:,].reshape(-1,output_dim)\n            #output: n x trg_seq_legth - 1 x trg_vocab_size\n            trg = trg[:,1:].reshape(-1)\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.623115Z","iopub.execute_input":"2024-06-05T18:34:46.623434Z","iopub.status.idle":"2024-06-05T18:34:46.631934Z","shell.execute_reply.started":"2024-06-05T18:34:46.623409Z","shell.execute_reply":"2024-06-05T18:34:46.630911Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:46.633154Z","iopub.execute_input":"2024-06-05T18:34:46.634895Z","iopub.status.idle":"2024-06-05T18:34:47.488481Z","shell.execute_reply.started":"2024-06-05T18:34:46.634868Z","shell.execute_reply":"2024-06-05T18:34:47.487587Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"n_epochs = 5\nbest_valid_loss = float(\"inf\")\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    train_loss = train_fn(\n        model,\n        train_data_loader,\n        optimizer,\n        criterion,\n        device,\n    )\n    valid_loss = evaluate_fn(\n        model,\n        valid_data_loader,\n        criterion,\n        device,\n    )\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), \"model.pt\")\n    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:34:47.489597Z","iopub.execute_input":"2024-06-05T18:34:47.490131Z","iopub.status.idle":"2024-06-05T18:35:07.043598Z","shell.execute_reply.started":"2024-06-05T18:34:47.490102Z","shell.execute_reply":"2024-06-05T18:35:07.042422Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":" 20%|██        | 1/5 [00:04<00:18,  4.71s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.062 | Train PPL:  21.375\n\tValid Loss:   0.795 | Valid PPL:   2.214\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 2/5 [00:08<00:12,  4.14s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.631 | Train PPL:   1.879\n\tValid Loss:   0.218 | Valid PPL:   1.244\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 3/5 [00:12<00:07,  3.95s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.219 | Train PPL:   1.245\n\tValid Loss:   0.069 | Valid PPL:   1.071\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 4/5 [00:15<00:03,  3.85s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.080 | Train PPL:   1.083\n\tValid Loss:   0.020 | Valid PPL:   1.020\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [00:19<00:00,  3.91s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.027 | Train PPL:   1.027\n\tValid Loss:   0.006 | Valid PPL:   1.006\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"model.pt\"))\ntest_loss = evaluate_fn(model, test_data_loader, criterion, device)\nprint(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:35:07.045375Z","iopub.execute_input":"2024-06-05T18:35:07.045667Z","iopub.status.idle":"2024-06-05T18:35:07.251442Z","shell.execute_reply.started":"2024-06-05T18:35:07.045642Z","shell.execute_reply":"2024-06-05T18:35:07.250312Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"| Test Loss: 0.005 | Test PPL:   1.005 |\n","output_type":"stream"}]},{"cell_type":"code","source":"def translate_sentence(\n    sentence,\n    model,\n    en_nlp,\n    de_nlp,\n    en_vocab,\n    de_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n    max_output_length=10,\n):\n    model.eval()\n    with torch.no_grad():\n        if isinstance(sentence, str):\n            tokens = [token.text for token in en_nlp.tokenizer(sentence)]\n        else:\n            tokens = [token for token in sentence]\n        if lower:\n            tokens = [token.lower() for token in tokens]\n        res = []\n        tokens = [sos_token] + tokens + [eos_token]\n        ids = en_vocab.lookup_indices(tokens)\n        src = torch.LongTensor(ids).unsqueeze(0).to(device)\n        tgt = torch.LongTensor(de_vocab.lookup_indices([sos_token])).unsqueeze(0).to(device)\n        for i in range(max_output_length):\n            output = model(src,tgt)\n            predicted_token = output[0,-1].argmax(-1).item()\n            res.append(predicted_token)\n            tgt = torch.cat((tgt, torch.tensor([[predicted_token]]).to(device)), dim=1)\n            if predicted_token == en_vocab[eos_token]:\n                break\n        tokens = de_vocab.lookup_tokens(res)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:36:32.371499Z","iopub.execute_input":"2024-06-05T18:36:32.371945Z","iopub.status.idle":"2024-06-05T18:36:32.383410Z","shell.execute_reply.started":"2024-06-05T18:36:32.371914Z","shell.execute_reply":"2024-06-05T18:36:32.382197Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"sentence = train_data[5]['en']\nprint(sentence)\ntranslate_sentence(\n    sentence,\n    model,\n    en_nlp,\n    vi_nlp,\n    en_vocab,\n    vi_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T18:36:32.958627Z","iopub.execute_input":"2024-06-05T18:36:32.959068Z","iopub.status.idle":"2024-06-05T18:36:33.073479Z","shell.execute_reply.started":"2024-06-05T18:36:32.959035Z","shell.execute_reply":"2024-06-05T18:36:33.072420Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"I promised Tom I'd wait.\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"['tôi', 'tôi', 'tôi', 'tôi', 'tôi', 'tôi', 'tôi', 'tôi', 'tôi', 'tôi']"},"metadata":{}}]}]}
{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8537196,"sourceType":"datasetVersion","datasetId":5099533}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyvi torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:31.847736Z","iopub.execute_input":"2024-06-07T08:20:31.848130Z","iopub.status.idle":"2024-06-07T08:20:44.018904Z","shell.execute_reply.started":"2024-06-07T08:20:31.848104Z","shell.execute_reply":"2024-06-07T08:20:44.017696Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyvi in /opt/conda/lib/python3.10/site-packages (0.1.1)\nRequirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\nRequirement already satisfied: sklearn-crfsuite in /opt/conda/lib/python3.10/site-packages (from pyvi) (0.3.6)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.2.0)\nRequirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.10)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.66.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nimport numpy as np\nimport spacy\nimport torchtext\nimport tqdm\nimport random\nfrom spacy.lang.vi import Vietnamese\nfrom spacy.lang.en import English\nfrom torch.utils.data import Dataset, random_split\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.021381Z","iopub.execute_input":"2024-06-07T08:20:44.022319Z","iopub.status.idle":"2024-06-07T08:20:44.028781Z","shell.execute_reply.started":"2024-06-07T08:20:44.022277Z","shell.execute_reply":"2024-06-07T08:20:44.027704Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"seed = 1234\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.029947Z","iopub.execute_input":"2024-06-07T08:20:44.030253Z","iopub.status.idle":"2024-06-07T08:20:44.041603Z","shell.execute_reply.started":"2024-06-07T08:20:44.030230Z","shell.execute_reply":"2024-06-07T08:20:44.040875Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"def load_data(path):\n    data = []\n    with open(path,'r') as file:\n        for line in file.readlines():\n            splitted_line = line.split('\\t')\n            eng = splitted_line[0]\n            vi = splitted_line[1]\n            data.append({'vi':vi, \n                         'en':eng})\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.043733Z","iopub.execute_input":"2024-06-07T08:20:44.044011Z","iopub.status.idle":"2024-06-07T08:20:44.053345Z","shell.execute_reply.started":"2024-06-07T08:20:44.043988Z","shell.execute_reply":"2024-06-07T08:20:44.052579Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, index):\n        return self.data[index]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.054495Z","iopub.execute_input":"2024-06-07T08:20:44.054767Z","iopub.status.idle":"2024-06-07T08:20:44.065007Z","shell.execute_reply.started":"2024-06-07T08:20:44.054745Z","shell.execute_reply":"2024-06-07T08:20:44.064203Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"dataset = CustomDataset(load_data('/kaggle/input/languagedata/data/vie.txt'))","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.066223Z","iopub.execute_input":"2024-06-07T08:20:44.066566Z","iopub.status.idle":"2024-06-07T08:20:44.110756Z","shell.execute_reply.started":"2024-06-07T08:20:44.066535Z","shell.execute_reply":"2024-06-07T08:20:44.110026Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"#7:2:1\ntotal_samples = len(dataset)\ntrain_size = int(0.8 * total_samples)\nval_size = int(0.1 * total_samples)\ntest_size = total_samples - train_size - val_size","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.111852Z","iopub.execute_input":"2024-06-07T08:20:44.112107Z","iopub.status.idle":"2024-06-07T08:20:44.118469Z","shell.execute_reply.started":"2024-06-07T08:20:44.112085Z","shell.execute_reply":"2024-06-07T08:20:44.117722Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"train_data, valid_data, test_data = random_split(dataset, [train_size, val_size, test_size])\nprint(\"Số lượng mẫu trong tập train:\", len(train_data))\nprint(\"Số lượng mẫu trong tập validation:\", len(valid_data))\nprint(\"Số lượng mẫu trong tập test:\", len(test_data))","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.119543Z","iopub.execute_input":"2024-06-07T08:20:44.119796Z","iopub.status.idle":"2024-06-07T08:20:44.129280Z","shell.execute_reply.started":"2024-06-07T08:20:44.119775Z","shell.execute_reply":"2024-06-07T08:20:44.128270Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"Số lượng mẫu trong tập train: 7542\nSố lượng mẫu trong tập validation: 942\nSố lượng mẫu trong tập test: 944\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.130311Z","iopub.execute_input":"2024-06-07T08:20:44.130692Z","iopub.status.idle":"2024-06-07T08:20:44.139689Z","shell.execute_reply.started":"2024-06-07T08:20:44.130657Z","shell.execute_reply":"2024-06-07T08:20:44.138857Z"},"trusted":true},"execution_count":127,"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?'}"},"metadata":{}}]},{"cell_type":"code","source":"en_nlp = English()\nvi_nlp = Vietnamese()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.144004Z","iopub.execute_input":"2024-06-07T08:20:44.144242Z","iopub.status.idle":"2024-06-07T08:20:44.361123Z","shell.execute_reply.started":"2024-06-07T08:20:44.144222Z","shell.execute_reply":"2024-06-07T08:20:44.360364Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"string = \"What a lovely day it is today!\"\n[token.text for token in en_nlp.tokenizer(string)]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.362250Z","iopub.execute_input":"2024-06-07T08:20:44.362607Z","iopub.status.idle":"2024-06-07T08:20:44.369609Z","shell.execute_reply.started":"2024-06-07T08:20:44.362571Z","shell.execute_reply":"2024-06-07T08:20:44.368683Z"},"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_example(example, en_nlp, vi_nlp, max_length, lower, sos_token, eos_token):\n    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n    vi_tokens = [token.text for token in vi_nlp.tokenizer(example[\"vi\"])][:max_length]\n    if lower:\n        en_tokens = [token.lower() for token in en_tokens]\n        vi_tokens = [token.lower() for token in vi_tokens]\n    en_tokens = [sos_token] + en_tokens + [eos_token]\n    vi_tokens = [sos_token] + vi_tokens + [eos_token]\n    example[\"en_tokens\"] = en_tokens\n    example[\"vi_tokens\"] = vi_tokens\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.370715Z","iopub.execute_input":"2024-06-07T08:20:44.371019Z","iopub.status.idle":"2024-06-07T08:20:44.382015Z","shell.execute_reply.started":"2024-06-07T08:20:44.370995Z","shell.execute_reply":"2024-06-07T08:20:44.381165Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"max_length = 50\nlower = True\nsos_token = \"<sos>\"\neos_token = \"<eos>\"\n\nfn_kwargs = {\n    \"en_nlp\": en_nlp,\n    \"vi_nlp\": vi_nlp,\n    \"max_length\": max_length,\n    \"lower\": lower,\n    \"sos_token\": sos_token,\n    \"eos_token\": eos_token,\n}\ntrain_data = [tokenize_example(example, **fn_kwargs) for example in train_data]\nvalid_data = [tokenize_example(example, **fn_kwargs) for example in valid_data]\ntest_data = [tokenize_example(example, **fn_kwargs) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:44.383186Z","iopub.execute_input":"2024-06-07T08:20:44.383554Z","iopub.status.idle":"2024-06-07T08:20:47.685992Z","shell.execute_reply.started":"2024-06-07T08:20:44.383518Z","shell.execute_reply":"2024-06-07T08:20:47.685214Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:47.686996Z","iopub.execute_input":"2024-06-07T08:20:47.687260Z","iopub.status.idle":"2024-06-07T08:20:47.693812Z","shell.execute_reply.started":"2024-06-07T08:20:47.687238Z","shell.execute_reply":"2024-06-07T08:20:47.692808Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?',\n 'en_tokens': ['<sos>',\n  'do',\n  'you',\n  'really',\n  'want',\n  'to',\n  'wear',\n  'that',\n  '?',\n  '<eos>'],\n 'vi_tokens': ['<sos>',\n  'bạn',\n  'thực sự',\n  'muốn',\n  'mặc',\n  'cái',\n  'đó',\n  'sao',\n  '?',\n  '<eos>']}"},"metadata":{}}]},{"cell_type":"code","source":"def yield_tokens(data,s):\n    for dct in data:\n        yield dct[s]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:47.694969Z","iopub.execute_input":"2024-06-07T08:20:47.695266Z","iopub.status.idle":"2024-06-07T08:20:47.704612Z","shell.execute_reply.started":"2024-06-07T08:20:47.695232Z","shell.execute_reply":"2024-06-07T08:20:47.703755Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"min_freq = 2\nunk_token = \"<unk>\"\npad_token = \"<pad>\"\n\nspecial_tokens = [\n    unk_token,\n    pad_token,\n    sos_token,\n    eos_token,\n]\n\nen_vocab = torchtext.vocab.build_vocab_from_iterator(\n    yield_tokens(train_data,'en_tokens'),\n    min_freq=min_freq,\n    specials=special_tokens,\n)\n\nvi_vocab = torchtext.vocab.build_vocab_from_iterator(\n    yield_tokens(train_data,'vi_tokens'),\n    min_freq=min_freq,\n    specials=special_tokens,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:47.705569Z","iopub.execute_input":"2024-06-07T08:20:47.705849Z","iopub.status.idle":"2024-06-07T08:20:47.930110Z","shell.execute_reply.started":"2024-06-07T08:20:47.705826Z","shell.execute_reply":"2024-06-07T08:20:47.929076Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"assert en_vocab[unk_token] == vi_vocab[unk_token]\nassert en_vocab[pad_token] == vi_vocab[pad_token]\n\nunk_index = en_vocab[unk_token]\npad_index = en_vocab[pad_token]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:47.931283Z","iopub.execute_input":"2024-06-07T08:20:47.931589Z","iopub.status.idle":"2024-06-07T08:20:47.936636Z","shell.execute_reply.started":"2024-06-07T08:20:47.931564Z","shell.execute_reply":"2024-06-07T08:20:47.935543Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"en_vocab.set_default_index(unk_index)\nvi_vocab.set_default_index(unk_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:47.937733Z","iopub.execute_input":"2024-06-07T08:20:47.937998Z","iopub.status.idle":"2024-06-07T08:20:47.946969Z","shell.execute_reply.started":"2024-06-07T08:20:47.937975Z","shell.execute_reply":"2024-06-07T08:20:47.946170Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\nen_vocab.lookup_indices(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:47.947914Z","iopub.execute_input":"2024-06-07T08:20:47.948147Z","iopub.status.idle":"2024-06-07T08:20:47.960509Z","shell.execute_reply.started":"2024-06-07T08:20:47.948127Z","shell.execute_reply":"2024-06-07T08:20:47.959457Z"},"trusted":true},"execution_count":137,"outputs":[{"execution_count":137,"output_type":"execute_result","data":{"text/plain":"[5, 173, 509, 0, 0]"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:47.961609Z","iopub.execute_input":"2024-06-07T08:20:47.961911Z","iopub.status.idle":"2024-06-07T08:20:47.974191Z","shell.execute_reply.started":"2024-06-07T08:20:47.961886Z","shell.execute_reply":"2024-06-07T08:20:47.973419Z"},"trusted":true},"execution_count":138,"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"['i', 'love', 'watching', '<unk>', '<unk>']"},"metadata":{}}]},{"cell_type":"code","source":"def numericalize_example(example, en_vocab, vi_vocab):\n    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n    vi_ids = vi_vocab.lookup_indices(example[\"vi_tokens\"])\n    example[\"en_ids\"] = en_ids\n    example[\"vi_ids\"] = vi_ids\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:47.975208Z","iopub.execute_input":"2024-06-07T08:20:47.975494Z","iopub.status.idle":"2024-06-07T08:20:47.983229Z","shell.execute_reply.started":"2024-06-07T08:20:47.975471Z","shell.execute_reply":"2024-06-07T08:20:47.982353Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"fn_kwargs = {\"en_vocab\": en_vocab, \"vi_vocab\": vi_vocab}\ntrain_data = [numericalize_example(example, **fn_kwargs) for example in train_data]\nvalid_data = [numericalize_example(example, **fn_kwargs) for example in valid_data]\ntest_data = [numericalize_example(example, **fn_kwargs) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:47.984415Z","iopub.execute_input":"2024-06-07T08:20:47.984738Z","iopub.status.idle":"2024-06-07T08:20:48.056969Z","shell.execute_reply.started":"2024-06-07T08:20:47.984707Z","shell.execute_reply":"2024-06-07T08:20:48.056079Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.058038Z","iopub.execute_input":"2024-06-07T08:20:48.058299Z","iopub.status.idle":"2024-06-07T08:20:48.065122Z","shell.execute_reply.started":"2024-06-07T08:20:48.058276Z","shell.execute_reply":"2024-06-07T08:20:48.064170Z"},"trusted":true},"execution_count":141,"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?',\n 'en_tokens': ['<sos>',\n  'do',\n  'you',\n  'really',\n  'want',\n  'to',\n  'wear',\n  'that',\n  '?',\n  '<eos>'],\n 'vi_tokens': ['<sos>',\n  'bạn',\n  'thực sự',\n  'muốn',\n  'mặc',\n  'cái',\n  'đó',\n  'sao',\n  '?',\n  '<eos>'],\n 'en_ids': [2, 14, 8, 88, 37, 6, 431, 15, 10, 3],\n 'vi_ids': [2, 8, 184, 30, 281, 34, 15, 97, 11, 3]}"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.lookup_tokens(train_data[0][\"en_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.066336Z","iopub.execute_input":"2024-06-07T08:20:48.067240Z","iopub.status.idle":"2024-06-07T08:20:48.075042Z","shell.execute_reply.started":"2024-06-07T08:20:48.067188Z","shell.execute_reply":"2024-06-07T08:20:48.074006Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"['<sos>', 'do', 'you', 'really', 'want', 'to', 'wear', 'that', '?', '<eos>']"},"metadata":{}}]},{"cell_type":"code","source":"def to_tensor(example):\n    example['en_ids'] = torch.tensor(np.array(example['en_ids']), dtype=torch.int64)\n    example['vi_ids'] = torch.tensor(np.array(example['vi_ids']), dtype=torch.int64)\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.076073Z","iopub.execute_input":"2024-06-07T08:20:48.076344Z","iopub.status.idle":"2024-06-07T08:20:48.083896Z","shell.execute_reply.started":"2024-06-07T08:20:48.076306Z","shell.execute_reply":"2024-06-07T08:20:48.083061Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"train_data = [to_tensor(example) for example in train_data]\nvalid_data = [to_tensor(example) for example in valid_data]\ntest_data = [to_tensor(example) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.085044Z","iopub.execute_input":"2024-06-07T08:20:48.085788Z","iopub.status.idle":"2024-06-07T08:20:48.283354Z","shell.execute_reply.started":"2024-06-07T08:20:48.085763Z","shell.execute_reply":"2024-06-07T08:20:48.282605Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"def get_collate_fn(pad_index, max_length):\n    def collate_fn(batch):\n        batch_en_ids = []\n        batch_vi_ids = []\n#         batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n#         batch_vi_ids = nn.utils.rnn.pad_sequence(batch_vi_ids, padding_value=pad_index)\n        for example in batch:\n            en_ids = example[\"en_ids\"]\n            vi_ids = example[\"vi_ids\"]\n            if len(en_ids) > max_length:\n                en_ids = en_ids[:max_length]\n            else:\n                en_ids = torch.cat((en_ids, torch.tensor([pad_index] * (max_length - len(en_ids)))))\n            if len(vi_ids) > max_length:\n                vi_ids = vi_ids[:max_length]\n            else:\n                vi_ids = torch.cat((vi_ids, torch.tensor([pad_index] * (max_length - len(vi_ids)))))\n            assert len(en_ids) == max_length\n            assert len(vi_ids) == max_length\n            batch_en_ids.append(en_ids)\n            batch_vi_ids.append(vi_ids)\n        batch = {\n            \"en_ids\": torch.stack(batch_en_ids),\n            \"vi_ids\": torch.stack(batch_vi_ids),\n        }\n        return batch\n\n    return collate_fn","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.284352Z","iopub.execute_input":"2024-06-07T08:20:48.284640Z","iopub.status.idle":"2024-06-07T08:20:48.293169Z","shell.execute_reply.started":"2024-06-07T08:20:48.284616Z","shell.execute_reply":"2024-06-07T08:20:48.292195Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"def get_data_loader(dataset, batch_size, pad_index, max_length, shuffle=False):\n    collate_fn = get_collate_fn(pad_index, max_length)\n    data_loader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        collate_fn=collate_fn,\n        shuffle=shuffle,\n    )\n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.298475Z","iopub.execute_input":"2024-06-07T08:20:48.298758Z","iopub.status.idle":"2024-06-07T08:20:48.307151Z","shell.execute_reply.started":"2024-06-07T08:20:48.298725Z","shell.execute_reply":"2024-06-07T08:20:48.306395Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nmax_length = 50\ntrain_data_loader = get_data_loader(train_data, batch_size, pad_index,max_length, shuffle=True)\nvalid_data_loader = get_data_loader(valid_data, batch_size, pad_index, max_length)\ntest_data_loader = get_data_loader(test_data, batch_size, pad_index, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.308355Z","iopub.execute_input":"2024-06-07T08:20:48.308668Z","iopub.status.idle":"2024-06-07T08:20:48.317852Z","shell.execute_reply.started":"2024-06-07T08:20:48.308643Z","shell.execute_reply":"2024-06-07T08:20:48.317108Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"class TokenAndPositionEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_dim, max_length, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.word_emb = nn.Embedding(\n            num_embeddings=vocab_size,\n            embedding_dim=embed_dim)\n        self.pos_emb = nn.Embedding(\n            num_embeddings=max_length,\n            embedding_dim=embed_dim\n        )\n\n    def forward(self, x):\n        N, seq_len = x.size()\n        positions = torch.arange(0, seq_len).expand(N, seq_len).to(self.device)\n        output1 = self.word_emb(x)\n        output2 = self.pos_emb(positions)\n        output =  output1 + output2\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.318889Z","iopub.execute_input":"2024-06-07T08:20:48.319151Z","iopub.status.idle":"2024-06-07T08:20:48.328993Z","shell.execute_reply.started":"2024-06-07T08:20:48.319128Z","shell.execute_reply":"2024-06-07T08:20:48.328107Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoderBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            batch_first = True\n        )\n        self.ffn = nn.Sequential(\n            nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n        )\n        self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.dropout_1 = nn.Dropout(p=dropout)\n        self.dropout_2 = nn.Dropout(p=dropout)\n\n    def forward(self, query, key, value):\n        attn_output, _ = self.attn(query, key, value)\n        attn_output = self.dropout_1(attn_output)\n        out_1 = self.layernorm_1(query + attn_output)\n        ffn_output = self.ffn(out_1)\n        ffn_output = self.dropout_2(ffn_output)\n        out_2 = self.layernorm_2(out_1 + ffn_output)\n        return out_2","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.330083Z","iopub.execute_input":"2024-06-07T08:20:48.330427Z","iopub.status.idle":"2024-06-07T08:20:48.343178Z","shell.execute_reply.started":"2024-06-07T08:20:48.330379Z","shell.execute_reply":"2024-06-07T08:20:48.342438Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(nn.Module):\n    def __init__(self, src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.embedding = TokenAndPositionEmbedding(src_vocab_size, embed_dim, max_length, device)\n        self.layers = nn.ModuleList(\n            [\n                TransformerEncoderBlock(embed_dim, num_heads, ff_dim, dropout) for i in range(num_layers)\n            ]\n        )\n\n    def forward(self, x):\n        output = self.embedding(x)\n        for layer in self.layers:\n            output = layer(output, output, output)\n        return output\n     ","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.344330Z","iopub.execute_input":"2024-06-07T08:20:48.344665Z","iopub.status.idle":"2024-06-07T08:20:48.353749Z","shell.execute_reply.started":"2024-06-07T08:20:48.344632Z","shell.execute_reply":"2024-06-07T08:20:48.352810Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoderBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            batch_first = True\n        )\n        self.cross_attn = nn.MultiheadAttention(\n            embed_dim = embed_dim,\n            num_heads = num_heads,\n            batch_first = True\n        )\n        self.ffn = nn.Sequential(\n            nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True)\n        )\n        self.layernorm_1  = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.layernorm_2  = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.layernorm_3  = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n        self.dropout_1 = nn.Dropout(p=dropout)\n        self.dropout_2 = nn.Dropout(p=dropout)\n        self.dropout_3 = nn.Dropout(p=dropout)\n\n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        attn_output, _ = self.attn(x, x, x, attn_mask=tgt_mask)\n        attn_output = self.dropout_1(attn_output)\n        out_1 = self.layernorm_1(x + attn_output)\n        attn_output, _ = self.cross_attn(out_1, enc_output, enc_output)\n        attn_output = self.dropout_2(attn_output)\n        out_2 = self.layernorm_2(out_1 + attn_output)\n        ffn_output = self.ffn(out_2)\n        ffn_output = self.dropout_3(ffn_output)\n        out_3 = self.layernorm_3(out_2 + ffn_output)\n        return out_3","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.354993Z","iopub.execute_input":"2024-06-07T08:20:48.355802Z","iopub.status.idle":"2024-06-07T08:20:48.371574Z","shell.execute_reply.started":"2024-06-07T08:20:48.355767Z","shell.execute_reply":"2024-06-07T08:20:48.370717Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoder(nn.Module):\n    def __init__(self, tgt_vocab_size, embed_dim, max_length, num_layers, num_aheads, ff_dim, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.embedding = TokenAndPositionEmbedding(tgt_vocab_size, embed_dim, max_length, device)\n        self.layers = nn.ModuleList(\n            [\n                TransformerDecoderBlock(embed_dim, num_heads, ff_dim, dropout) for i in range(num_layers)\n            ]\n        )\n\n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        output = self.embedding(x)\n        for layer in self.layers:\n            output = layer(output, enc_output, src_mask, tgt_mask)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.372534Z","iopub.execute_input":"2024-06-07T08:20:48.372808Z","iopub.status.idle":"2024-06-07T08:20:48.385883Z","shell.execute_reply.started":"2024-06-07T08:20:48.372786Z","shell.execute_reply":"2024-06-07T08:20:48.385065Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.encoder = TransformerEncoder(src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device)\n        self.decoder = TransformerDecoder(tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device)\n        self.fc = nn.Linear(embed_dim, tgt_vocab_size)\n\n    def generate_mask(self, src, tgt):\n        src_seq_len = src.shape[1]\n        tgt_seq_len = tgt.shape[1]\n\n        src_mask = torch.zeros((src_seq_len, src_seq_len), device=self.device).type(torch.bool)\n        tgt_mask = (torch.triu(torch.ones((tgt_seq_len, tgt_seq_len), device=self.device).type(torch.bool)) == 1).transpose(0,1)\n        tgt_mask = tgt_mask.float().masked_fill(tgt_mask == 0, float('-inf')).masked_fill(tgt_mask == 1, float(0.0))\n        return src_mask, tgt_mask\n\n    def forward(self, src, tgt):\n        src_mask, tgt_mask = self.generate_mask(src, tgt)\n        enc_output = self.encoder(src)\n        dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n        output = self.fc(dec_output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:20:48.386992Z","iopub.execute_input":"2024-06-07T08:20:48.387250Z","iopub.status.idle":"2024-06-07T08:20:48.399714Z","shell.execute_reply.started":"2024-06-07T08:20:48.387226Z","shell.execute_reply":"2024-06-07T08:20:48.398836Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"src_vocab_size = len(en_vocab)\ntgt_vocab_size = len(vi_vocab)\nembed_dim = 512\nmax_length = 50\nnum_layers = 6\nnum_heads = 8\nff_dim = 2048\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndropout = 0.2\nmodel = Transformer(src_vocab_size, tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:25:26.038292Z","iopub.execute_input":"2024-06-07T08:25:26.039220Z","iopub.status.idle":"2024-06-07T08:25:26.556418Z","shell.execute_reply.started":"2024-06-07T08:25:26.039186Z","shell.execute_reply":"2024-06-07T08:25:26.555592Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:25:26.558205Z","iopub.execute_input":"2024-06-07T08:25:26.558651Z","iopub.status.idle":"2024-06-07T08:25:26.564753Z","shell.execute_reply.started":"2024-06-07T08:25:26.558618Z","shell.execute_reply":"2024-06-07T08:25:26.563944Z"},"trusted":true},"execution_count":161,"outputs":[{"name":"stdout","text":"Transformer(\n  (encoder): TransformerEncoder(\n    (embedding): TokenAndPositionEmbedding(\n      (word_emb): Embedding(2187, 512)\n      (pos_emb): Embedding(50, 512)\n    )\n    (layers): ModuleList(\n      (0-5): 6 x TransformerEncoderBlock(\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ffn): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (layernorm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (layernorm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (dropout_1): Dropout(p=0.2, inplace=False)\n        (dropout_2): Dropout(p=0.2, inplace=False)\n      )\n    )\n  )\n  (decoder): TransformerDecoder(\n    (embedding): TokenAndPositionEmbedding(\n      (word_emb): Embedding(2065, 512)\n      (pos_emb): Embedding(50, 512)\n    )\n    (layers): ModuleList(\n      (0-5): 6 x TransformerDecoderBlock(\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ffn): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (layernorm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (layernorm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (layernorm_3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (dropout_1): Dropout(p=0.2, inplace=False)\n        (dropout_2): Dropout(p=0.2, inplace=False)\n        (dropout_3): Dropout(p=0.2, inplace=False)\n      )\n    )\n  )\n  (fc): Linear(in_features=512, out_features=2065, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_fn(model, data_loader, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(data_loader):\n        src = batch['en_ids'].to(device)\n        trg = batch['vi_ids'].to(device)\n        #src: n x src_seq_length\n        #trg: n x trg_seq_length\n        optimizer.zero_grad()\n        output = model(src, trg[:,:-1])\n        #output: n x trg_seq_length x trg_vocab_size\n        output_dim = output.shape[-1]\n        output = output.reshape(-1,output_dim)\n        #output: (n * trg_seq_length - 1) x trg_vocab_size\n        trg = trg[:,1:].reshape(-1)\n        #trg: n x trg_seq_length-1\n        loss = criterion(output, trg)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:25:26.856755Z","iopub.execute_input":"2024-06-07T08:25:26.857120Z","iopub.status.idle":"2024-06-07T08:25:26.864654Z","shell.execute_reply.started":"2024-06-07T08:25:26.857092Z","shell.execute_reply":"2024-06-07T08:25:26.863688Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"def evaluate_fn(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for i, batch in enumerate(data_loader):\n            src = batch['en_ids'].to(device)\n            trg = batch['vi_ids'].to(device)\n            #src: n x src_seq_length\n            #trg: n x trg_seq_length\n            output = model(src, trg[:,:-1])\n            output_dim = output.shape[-1]\n            output = output.reshape(-1,output_dim)\n            #output: n x trg_seq_legth - 1 x trg_vocab_size\n            trg = trg[:,1:].reshape(-1)\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:25:27.258457Z","iopub.execute_input":"2024-06-07T08:25:27.258808Z","iopub.status.idle":"2024-06-07T08:25:27.266095Z","shell.execute_reply.started":"2024-06-07T08:25:27.258780Z","shell.execute_reply":"2024-06-07T08:25:27.265138Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"for p in model.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\noptimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9,0.98), eps=1e-9)\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:25:27.800378Z","iopub.execute_input":"2024-06-07T08:25:27.800764Z","iopub.status.idle":"2024-06-07T08:25:27.811182Z","shell.execute_reply.started":"2024-06-07T08:25:27.800723Z","shell.execute_reply":"2024-06-07T08:25:27.810390Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"n_epochs = 100\nbest_valid_loss = float(\"inf\")\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    train_loss = train_fn(\n        model,\n        train_data_loader,\n        optimizer,\n        criterion,\n        device,\n    )\n    valid_loss = evaluate_fn(\n        model,\n        valid_data_loader,\n        criterion,\n        device,\n    )\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), \"model.pt\")\n    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-07T08:25:28.295529Z","iopub.execute_input":"2024-06-07T08:25:28.295898Z","iopub.status.idle":"2024-06-07T08:59:01.150553Z","shell.execute_reply.started":"2024-06-07T08:25:28.295871Z","shell.execute_reply":"2024-06-07T08:59:01.149466Z"},"trusted":true},"execution_count":165,"outputs":[{"name":"stderr","text":"  1%|          | 1/100 [00:20<33:39, 20.40s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   5.476 | Train PPL: 238.904\n\tValid Loss:   4.798 | Valid PPL: 121.263\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 2/100 [00:40<33:17, 20.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.730 | Train PPL: 113.339\n\tValid Loss:   4.502 | Valid PPL:  90.161\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 3/100 [01:01<32:58, 20.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.435 | Train PPL:  84.327\n\tValid Loss:   4.255 | Valid PPL:  70.461\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 4/100 [01:21<32:37, 20.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.180 | Train PPL:  65.388\n\tValid Loss:   4.059 | Valid PPL:  57.930\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 5/100 [01:41<32:17, 20.40s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.949 | Train PPL:  51.896\n\tValid Loss:   3.885 | Valid PPL:  48.671\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 6/100 [02:02<31:58, 20.41s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.717 | Train PPL:  41.129\n\tValid Loss:   3.683 | Valid PPL:  39.767\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 7/100 [02:22<31:38, 20.41s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.513 | Train PPL:  33.548\n\tValid Loss:   3.565 | Valid PPL:  35.344\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 8/100 [02:43<31:17, 20.41s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.341 | Train PPL:  28.261\n\tValid Loss:   3.426 | Valid PPL:  30.748\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 9/100 [03:03<30:57, 20.41s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.152 | Train PPL:  23.390\n\tValid Loss:   3.300 | Valid PPL:  27.122\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 10/100 [03:24<30:36, 20.41s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.992 | Train PPL:  19.928\n\tValid Loss:   3.238 | Valid PPL:  25.493\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 11/100 [03:44<30:16, 20.41s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.834 | Train PPL:  17.013\n\tValid Loss:   3.141 | Valid PPL:  23.135\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 12/100 [04:04<29:55, 20.40s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.675 | Train PPL:  14.506\n\tValid Loss:   3.017 | Valid PPL:  20.435\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 13/100 [04:25<29:34, 20.40s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.530 | Train PPL:  12.558\n\tValid Loss:   2.952 | Valid PPL:  19.153\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 14/100 [04:45<29:13, 20.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.395 | Train PPL:  10.966\n\tValid Loss:   2.895 | Valid PPL:  18.080\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 15/100 [05:05<28:53, 20.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.258 | Train PPL:   9.559\n\tValid Loss:   2.857 | Valid PPL:  17.408\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 16/100 [05:26<28:32, 20.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.127 | Train PPL:   8.392\n\tValid Loss:   2.815 | Valid PPL:  16.693\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 17/100 [05:46<28:12, 20.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.007 | Train PPL:   7.440\n\tValid Loss:   2.785 | Valid PPL:  16.206\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 18/100 [06:07<27:51, 20.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.889 | Train PPL:   6.613\n\tValid Loss:   2.747 | Valid PPL:  15.602\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 19/100 [06:27<27:31, 20.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.775 | Train PPL:   5.900\n\tValid Loss:   2.685 | Valid PPL:  14.657\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 20/100 [06:47<27:02, 20.28s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.668 | Train PPL:   5.303\n\tValid Loss:   2.721 | Valid PPL:  15.202\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 21/100 [07:07<26:44, 20.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.563 | Train PPL:   4.771\n\tValid Loss:   2.678 | Valid PPL:  14.561\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 22/100 [07:27<26:17, 20.23s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.460 | Train PPL:   4.307\n\tValid Loss:   2.686 | Valid PPL:  14.670\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 23/100 [07:48<26:01, 20.27s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.360 | Train PPL:   3.895\n\tValid Loss:   2.671 | Valid PPL:  14.456\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 24/100 [08:08<25:43, 20.31s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.278 | Train PPL:   3.590\n\tValid Loss:   2.658 | Valid PPL:  14.262\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 25/100 [08:29<25:25, 20.34s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.189 | Train PPL:   3.282\n\tValid Loss:   2.641 | Valid PPL:  14.031\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 26/100 [08:49<24:58, 20.25s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.106 | Train PPL:   3.021\n\tValid Loss:   2.646 | Valid PPL:  14.102\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 27/100 [09:09<24:33, 20.18s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.034 | Train PPL:   2.812\n\tValid Loss:   2.656 | Valid PPL:  14.246\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 28/100 [09:29<24:09, 20.14s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.953 | Train PPL:   2.593\n\tValid Loss:   2.657 | Valid PPL:  14.249\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 29/100 [09:49<23:47, 20.10s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.883 | Train PPL:   2.419\n\tValid Loss:   2.676 | Valid PPL:  14.525\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 30/100 [10:09<23:25, 20.08s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.825 | Train PPL:   2.281\n\tValid Loss:   2.703 | Valid PPL:  14.920\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 31/100 [10:29<23:04, 20.06s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.760 | Train PPL:   2.139\n\tValid Loss:   2.680 | Valid PPL:  14.586\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 32/100 [10:49<22:43, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.708 | Train PPL:   2.030\n\tValid Loss:   2.716 | Valid PPL:  15.127\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 33/100 [11:09<22:23, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.652 | Train PPL:   1.920\n\tValid Loss:   2.757 | Valid PPL:  15.746\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 34/100 [11:29<22:02, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.599 | Train PPL:   1.821\n\tValid Loss:   2.746 | Valid PPL:  15.586\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 35/100 [11:49<21:42, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.557 | Train PPL:   1.745\n\tValid Loss:   2.728 | Valid PPL:  15.305\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 36/100 [12:09<21:22, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.516 | Train PPL:   1.675\n\tValid Loss:   2.776 | Valid PPL:  16.062\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 37/100 [12:29<21:03, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.470 | Train PPL:   1.601\n\tValid Loss:   2.783 | Valid PPL:  16.173\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 38/100 [12:49<20:43, 20.06s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.438 | Train PPL:   1.549\n\tValid Loss:   2.790 | Valid PPL:  16.285\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 39/100 [13:09<20:23, 20.06s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.400 | Train PPL:   1.492\n\tValid Loss:   2.837 | Valid PPL:  17.072\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 40/100 [13:29<20:03, 20.06s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.375 | Train PPL:   1.454\n\tValid Loss:   2.829 | Valid PPL:  16.921\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 41/100 [13:49<19:43, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.347 | Train PPL:   1.415\n\tValid Loss:   2.857 | Valid PPL:  17.416\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 42/100 [14:09<19:24, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.323 | Train PPL:   1.381\n\tValid Loss:   2.915 | Valid PPL:  18.457\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 43/100 [14:30<19:03, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.298 | Train PPL:   1.347\n\tValid Loss:   2.967 | Valid PPL:  19.433\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 44/100 [14:50<18:43, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.282 | Train PPL:   1.326\n\tValid Loss:   2.910 | Valid PPL:  18.361\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 45/100 [15:10<18:23, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.262 | Train PPL:   1.300\n\tValid Loss:   2.932 | Valid PPL:  18.773\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▌     | 46/100 [15:30<18:03, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.246 | Train PPL:   1.278\n\tValid Loss:   3.002 | Valid PPL:  20.119\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 47/100 [15:50<17:43, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.235 | Train PPL:   1.265\n\tValid Loss:   2.953 | Valid PPL:  19.156\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 48/100 [16:10<17:23, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.224 | Train PPL:   1.251\n\tValid Loss:   3.024 | Valid PPL:  20.564\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 49/100 [16:30<17:03, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.217 | Train PPL:   1.242\n\tValid Loss:   3.035 | Valid PPL:  20.791\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 50/100 [16:50<16:43, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.205 | Train PPL:   1.227\n\tValid Loss:   3.050 | Valid PPL:  21.120\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 51/100 [17:10<16:23, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.195 | Train PPL:   1.216\n\tValid Loss:   3.039 | Valid PPL:  20.889\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 52/100 [17:30<16:03, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.191 | Train PPL:   1.210\n\tValid Loss:   3.043 | Valid PPL:  20.968\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 53/100 [17:50<15:43, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.180 | Train PPL:   1.197\n\tValid Loss:   3.075 | Valid PPL:  21.660\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 54/100 [18:10<15:23, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.176 | Train PPL:   1.193\n\tValid Loss:   3.107 | Valid PPL:  22.358\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 55/100 [18:30<15:03, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.169 | Train PPL:   1.184\n\tValid Loss:   3.090 | Valid PPL:  21.968\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 56/100 [18:50<14:43, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.164 | Train PPL:   1.178\n\tValid Loss:   3.098 | Valid PPL:  22.144\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 57/100 [19:11<14:23, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.161 | Train PPL:   1.175\n\tValid Loss:   3.135 | Valid PPL:  22.981\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 58/100 [19:31<14:02, 20.07s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.160 | Train PPL:   1.173\n\tValid Loss:   3.132 | Valid PPL:  22.925\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 59/100 [19:51<13:42, 20.06s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.153 | Train PPL:   1.166\n\tValid Loss:   3.127 | Valid PPL:  22.816\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 60/100 [20:11<13:21, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.151 | Train PPL:   1.163\n\tValid Loss:   3.147 | Valid PPL:  23.255\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 61/100 [20:31<13:01, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.145 | Train PPL:   1.156\n\tValid Loss:   3.146 | Valid PPL:  23.248\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 62/100 [20:51<12:41, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.148 | Train PPL:   1.159\n\tValid Loss:   3.149 | Valid PPL:  23.303\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 63/100 [21:11<12:21, 20.03s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.140 | Train PPL:   1.151\n\tValid Loss:   3.194 | Valid PPL:  24.378\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 64/100 [21:31<12:01, 20.03s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.141 | Train PPL:   1.151\n\tValid Loss:   3.174 | Valid PPL:  23.892\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 65/100 [21:51<11:41, 20.03s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.138 | Train PPL:   1.148\n\tValid Loss:   3.196 | Valid PPL:  24.425\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 66/100 [22:11<11:21, 20.03s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.134 | Train PPL:   1.144\n\tValid Loss:   3.262 | Valid PPL:  26.089\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 67/100 [22:31<11:01, 20.03s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.129 | Train PPL:   1.138\n\tValid Loss:   3.204 | Valid PPL:  24.631\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 68/100 [22:51<10:41, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.131 | Train PPL:   1.140\n\tValid Loss:   3.259 | Valid PPL:  26.018\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 69/100 [23:11<10:21, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.132 | Train PPL:   1.141\n\tValid Loss:   3.239 | Valid PPL:  25.517\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 70/100 [23:31<10:01, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.128 | Train PPL:   1.136\n\tValid Loss:   3.243 | Valid PPL:  25.616\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 71/100 [23:51<09:41, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.124 | Train PPL:   1.132\n\tValid Loss:   3.234 | Valid PPL:  25.372\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 72/100 [24:11<09:21, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.121 | Train PPL:   1.129\n\tValid Loss:   3.232 | Valid PPL:  25.324\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 73/100 [24:31<09:01, 20.06s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.124 | Train PPL:   1.132\n\tValid Loss:   3.253 | Valid PPL:  25.863\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 74/100 [24:51<08:41, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.121 | Train PPL:   1.128\n\tValid Loss:   3.265 | Valid PPL:  26.188\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 75/100 [25:11<08:21, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.114 | Train PPL:   1.121\n\tValid Loss:   3.289 | Valid PPL:  26.811\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 76/100 [25:31<08:01, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.119 | Train PPL:   1.126\n\tValid Loss:   3.294 | Valid PPL:  26.946\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 77/100 [25:51<07:41, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.113 | Train PPL:   1.120\n\tValid Loss:   3.299 | Valid PPL:  27.078\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 78/100 [26:11<07:21, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.114 | Train PPL:   1.121\n\tValid Loss:   3.284 | Valid PPL:  26.673\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 79/100 [26:31<07:00, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.116 | Train PPL:   1.123\n\tValid Loss:   3.319 | Valid PPL:  27.625\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 80/100 [26:52<06:40, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.112 | Train PPL:   1.118\n\tValid Loss:   3.308 | Valid PPL:  27.338\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 81/100 [27:12<06:20, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.110 | Train PPL:   1.117\n\tValid Loss:   3.357 | Valid PPL:  28.716\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 82/100 [27:32<06:00, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.109 | Train PPL:   1.115\n\tValid Loss:   3.310 | Valid PPL:  27.387\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 83/100 [27:52<05:40, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.110 | Train PPL:   1.116\n\tValid Loss:   3.339 | Valid PPL:  28.182\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 84/100 [28:12<05:20, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.106 | Train PPL:   1.112\n\tValid Loss:   3.361 | Valid PPL:  28.828\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 85/100 [28:32<05:00, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.106 | Train PPL:   1.112\n\tValid Loss:   3.355 | Valid PPL:  28.637\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 86/100 [28:52<04:40, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.107 | Train PPL:   1.113\n\tValid Loss:   3.376 | Valid PPL:  29.264\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 87/100 [29:12<04:20, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.106 | Train PPL:   1.112\n\tValid Loss:   3.295 | Valid PPL:  26.980\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 88/100 [29:32<04:00, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.103 | Train PPL:   1.109\n\tValid Loss:   3.346 | Valid PPL:  28.387\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 89/100 [29:52<03:40, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.102 | Train PPL:   1.108\n\tValid Loss:   3.297 | Valid PPL:  27.044\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 90/100 [30:12<03:20, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.101 | Train PPL:   1.107\n\tValid Loss:   3.403 | Valid PPL:  30.064\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 91/100 [30:32<03:00, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.099 | Train PPL:   1.104\n\tValid Loss:   3.397 | Valid PPL:  29.866\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 92/100 [30:52<02:40, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.099 | Train PPL:   1.104\n\tValid Loss:   3.349 | Valid PPL:  28.478\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 93/100 [31:12<02:20, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.100 | Train PPL:   1.105\n\tValid Loss:   3.322 | Valid PPL:  27.727\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 94/100 [31:32<02:00, 20.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.095 | Train PPL:   1.100\n\tValid Loss:   3.386 | Valid PPL:  29.551\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 95/100 [31:52<01:40, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.098 | Train PPL:   1.103\n\tValid Loss:   3.399 | Valid PPL:  29.944\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 96/100 [32:12<01:20, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.098 | Train PPL:   1.103\n\tValid Loss:   3.371 | Valid PPL:  29.119\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 97/100 [32:32<01:00, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.093 | Train PPL:   1.097\n\tValid Loss:   3.400 | Valid PPL:  29.956\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 98/100 [32:52<00:40, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.093 | Train PPL:   1.097\n\tValid Loss:   3.434 | Valid PPL:  30.987\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▉| 99/100 [33:12<00:20, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.095 | Train PPL:   1.100\n\tValid Loss:   3.410 | Valid PPL:  30.276\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [33:32<00:00, 20.13s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.092 | Train PPL:   1.097\n\tValid Loss:   3.406 | Valid PPL:  30.139\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"model.pt\"))\ntest_loss = evaluate_fn(model, test_data_loader, criterion, device)\nprint(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")","metadata":{"execution":{"iopub.status.busy":"2024-06-07T09:01:00.096792Z","iopub.execute_input":"2024-06-07T09:01:00.097171Z","iopub.status.idle":"2024-06-07T09:01:01.057426Z","shell.execute_reply.started":"2024-06-07T09:01:00.097140Z","shell.execute_reply":"2024-06-07T09:01:01.056344Z"},"trusted":true},"execution_count":173,"outputs":[{"name":"stdout","text":"| Test Loss: 2.634 | Test PPL:  13.924 |\n","output_type":"stream"}]},{"cell_type":"code","source":"def translate_sentence(\n    sentence,\n    model,\n    en_nlp,\n    de_nlp,\n    en_vocab,\n    de_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n    max_output_length=20,\n):\n    model.eval()\n    with torch.no_grad():\n        if isinstance(sentence, str):\n            tokens = [token.text for token in en_nlp.tokenizer(sentence)]\n        else:\n            tokens = [token for token in sentence]\n        if lower:\n            tokens = [token.lower() for token in tokens]\n        tokens = [sos_token] + tokens + [eos_token]\n        ids = en_vocab.lookup_indices(tokens)\n        src = torch.LongTensor(ids).unsqueeze(0).to(device)\n        encoder_output = model.encoder(src)\n        tgt = torch.ones(1, max_output_length).type_as(src.data)\n        next_symbol = vi_vocab.get_stoi()[sos_token]\n        for i in range(max_output_length):\n            tgt[0][i] = next_symbol\n            src_mask,tgt_mask = model.generate_mask(src, tgt)\n            decoder_output = model.decoder(tgt,encoder_output,src_mask,tgt_mask)\n            predicted_token = decoder_output[0,i].argmax(-1).item()\n            next_symbol = predicted_token\n            if predicted_token == en_vocab[eos_token]:\n                break\n        try:\n            eos_idx = int(torch.where(tgt[0] == vi_vocab.get_stoi()[eos_token])[0][0])\n            tgt = tgt[0][:eos_idx].unsqueeze(0)\n            print(eos_idx)\n        except:\n            pass\n        output = model(src, tgt)\n        output = output[0].argmax(-1).squeeze().detach().cpu().numpy()\n        tokens = de_vocab.lookup_tokens(output)\n    return \" \".join(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T09:01:04.043001Z","iopub.execute_input":"2024-06-07T09:01:04.043724Z","iopub.status.idle":"2024-06-07T09:01:04.055040Z","shell.execute_reply.started":"2024-06-07T09:01:04.043693Z","shell.execute_reply":"2024-06-07T09:01:04.054180Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"# def translate_sentence(\n#     sentence,\n#     model,\n#     en_nlp,\n#     de_nlp,\n#     en_vocab,\n#     de_vocab,\n#     lower,\n#     sos_token,\n#     eos_token,\n#     device,\n#     max_output_length=20,\n# ):\n#     model.eval()\n#     with torch.no_grad():\n#         if isinstance(sentence, str):\n#             tokens = [token.text for token in en_nlp.tokenizer(sentence)]\n#         else:\n#             tokens = [token for token in sentence]\n#         if lower:\n#             tokens = [token.lower() for token in tokens]\n#         res = []\n#         tokens = [sos_token] + tokens + [eos_token]\n#         ids = en_vocab.lookup_indices(tokens)\n#         print(ids)\n#         src = torch.LongTensor(ids).unsqueeze(0).to(device)\n#         encoder_output = model.encoder(src)\n#         tgt = torch.LongTensor(de_vocab.lookup_indices([sos_token])).unsqueeze(0).to(device)\n#         for i in range(max_output_length):\n#             src_mask,tgt_mask = model.generate_mask(src, tgt)\n#             decoder_output = model.decoder(tgt,encoder_output,src_mask,tgt_mask)\n#             predicted_token = decoder_output[0,i].argmax(-1).item()\n#             res.append(predicted_token)\n#             tgt = torch.cat((tgt, torch.tensor([[predicted_token]]).to(device)), dim=1)\n#             if predicted_token == en_vocab[eos_token]:\n#                 break\n# #         output = tgt[0].cpu().numpy()\n#         output = model(src,torch.tensor(res).unsqueeze(0).to(device))\n#         output = output[0].argmax(-1).squeeze().detach().cpu().numpy()\n#         tokens = de_vocab.lookup_tokens(output)\n#     return \" \".join(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T09:00:40.487120Z","iopub.execute_input":"2024-06-07T09:00:40.487565Z","iopub.status.idle":"2024-06-07T09:00:40.499446Z","shell.execute_reply.started":"2024-06-07T09:00:40.487533Z","shell.execute_reply":"2024-06-07T09:00:40.498365Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"for i in range(10,20):\n    sentence = train_data[i]['en']\n    print(sentence)\n    print(translate_sentence(\n        sentence,\n        model,\n        en_nlp,\n        vi_nlp,\n        en_vocab,\n        vi_vocab,\n        lower,\n        sos_token,\n        eos_token,\n        device,\n    ))\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T09:01:30.055365Z","iopub.execute_input":"2024-06-07T09:01:30.055745Z","iopub.status.idle":"2024-06-07T09:01:31.594941Z","shell.execute_reply.started":"2024-06-07T09:01:30.055717Z","shell.execute_reply":"2024-06-07T09:01:31.593948Z"},"trusted":true},"execution_count":176,"outputs":[{"name":"stdout","text":"Tom is the person who killed Mary.\ntom như tom là là là gặp tom của tom tom là tom . . là là tom . tom\n\nCould you please hurry up, sir?\nnếu , , , , được được xe xe bạn , là người bạn , người . , , người\n\nThey're drunk.\nhọ là là xem <unk> pháp pháp anh . . . . . . . . . . . .\n\nI had broken my glasses, so that I couldn't see the blackboard.\ntôi như tôi , , , , tôi <unk> , khỏi , khỏi . thứ , . , , tôi\n\nTom doesn't know a lot about Boston.\ntom như là , , , không tên boston tom , , , tom , , . , , tôi\n\nTo see him talk, you might think he's a girl.\nnếu như bạn , , bạn , , , , , , , , nó , . nó , tôi\n\nI thought I could change your mind.\ntôi của tôi tôi tôi tôi tôi tôi với tôi . tôi . tôi mình . mình tôi . tôi\n\nTom apologized to me for his rudeness.\ntom như là với tôi , tôi với , tôi , tôi với tôi tôi , với . . tôi\n\nMusic is a gift from God.\ntrong của của của tom tom họ của của . của và nó . nó của của . . được\n\nYou should memorize as many English words as possible.\ncậu như như là là khỏi về tiếng hơn . được là khỏi . nó . . . . nó\n\n","output_type":"stream"}]}]}